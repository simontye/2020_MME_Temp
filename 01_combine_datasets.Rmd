---
title: "combine datasets"
author: "fishkill friends"
date: "2021/02/02"
output: github_document
---

### Background

This file combines fishkill data from Minnesota (Phelps et al. 2019) and Wisconsin (Till et al. 2019) with concurrent (2003-2014) and future (2041-2059; 2081-2099) air and water temperature estimates. First, each fishkill event (2003-2014) was attributed to a major cause (anthropogenic, infectious, summerkill, unknown, winterkill) and associated with a specific waterbody. Next, I obtained concurrent air and water temperature estimates (2003-2014) from PRISM (~8 km resolution) and Winslow et al. (2017), respectively, for each waterbody. I then obtained future air and water temperature estimates (2041-2059; 2081-2099) from the NOAA GFDL CM3 model (~8 km resolution) and Winslow et al. (2017), respectively. Both of these temperature estimates are based on RCP 8.5 projections. Lastly, these datasets also include precipitation, snowfall, and 2010 census data. After running this script, the historical (df.historical) and future (df.future) datasets are ready for modeling (02_prepare_models.Rmd).

### Folders in data/raw:

- `census_data`:                   Data from US Census Bureau (2010)
- `lake_shapes`:                   GIS outlines of lake shapes
- `PRISM_precip`:                  Precipitation estimates (http://prism.oregonstate.edu)
- `temp_air`:                      Historical and future air temperature estimates from NOAA and PRISM (http://prism.oregonstate.edu)
- `wisconsin_outline`:             GIS outlines of state

### Files in data/raw:

- `FishKill_Master.csv`:           Minnesota fishkill data from Phelps et al. (2019)
- `fish_kill_data_10_24_2018.csv`: Wisconsin fishkill data from Till et al. (2019)
- `Site_ID.csv`:                   Waterbody information for most of the upper midwest
- `WI_Site.csv`:                   Waterbody information for Wisconsin
- `temp_water.csv`:                Historical water temperature data (1980-2013) for upper midwest lakes from Winslow et al. (2017)
- `prism_1.csv`:                   Historical air temperature data (2003-2013) for the upper midwest from PRISM
- `prism_2.csv`:                   Historical air temperature data (2003-2013) for the upper midwest from PRISM
- `ACCESS_thermal_metrics.tsv`:    Future water temperature data (2041-2059; 2081-2099)
- `localities.csv`:                Coordinates for waterbodies in the upper midwest
- `mme_temp_missing.kml`:          Locations of waterbodies that had missing coordinates
- `2010_census.csv`:               Data from US Census Bata (2010)

### Step 1: Load packages and data

Note that the `lakeattribute` package requires a remote install.

```{r: Load packages and data}
#remotes::install_github("USGS-R/lakeattributes")

# Load packages
library(plyr)
library(remotes)
library(lakeattributes)
library(data.table)
library(tidyverse)
library(sp)
library(rgeos)
library(sf)
library(ggmap)
library(ggspatial)
library(rgdal)
library(lubridate)
library(raster)
library(naniar)
library(compareDF)
library(maps)
library(ncdf4)
library(anchors)
library(maptools)
library(stringr)

# Reset global environment
rm(list = ls())

# Set working directory
setwd("/Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp")

# Load files
mn.fish      <- read.csv(file = "data/raw/Fishkill_Master.csv", head = TRUE, sep = ",")
wi.fish      <- read.csv(file = "data/raw/fish_kill_data_10_24_2018.csv", head = TRUE, sep = ",")
wi.site      <- read.csv(file = "data/raw/WI_Site.csv", head = TRUE, sep = ",")
site.id      <- read.csv(file = "data/raw/Site_ID.csv", head = TRUE, sep = ",")
hist.water   <- read.csv(file = "data/raw/temp_water.csv", head = TRUE, sep = ",")
hist.air.1   <- read.csv(file = "data/raw/prism_1.csv", head = TRUE, sep = ",")
hist.air.2   <- read.csv(file = "data/raw/prism_2.csv", head = TRUE, sep = ",")
census       <- read.csv(file = "data/raw/2010_census.csv", head = TRUE, sep = ",")
```

### Step 2: Add Minnesota fishkill data

This reformats the MN fishkill dataset. First, this combines fishkills that occurred in the same waterbody and month into a single event. I manually verified each of these events so that all affected taxa were accounted for and the most frequent cause was considered the cause of the combined event. All affected taxa are organized by family and, if possible, species. Second, this associates each fishkill with the nearest waterbody centroid using the unique identifier "site_id". Till et al., (2019) used "WBIC" as the unique identifier, however this idenfitier is state-specific to Wisconsin and "site_id", from the National Hydrologic Database (NHD), can be used across both states. Third, this calculates the species and family richness for each fishkill event.

```{r: Add Minnesota fishkill data}
# Merges waterbody information, reformats columns, and removes locations without coordinates
site.id <- site.id %>%
  left_join(., wi.site, by = "site_id", all = TRUE) %>%
  rename_all(tolower) %>%
  mutate_all(tolower) %>%
  mutate(lat  = as.numeric(lat),
         long = as.numeric(long),
         site = as.numeric(1:10962)) %>%
  subset(., !is.na(lat)) %>% # removes locations without coordinates
  dplyr::select(., -c("prmnn_i", "gnis_id", "reachcd", "ftype", "fcode", "x")) # removes unnecessary column

# Removes fishkill events outside of the study period, renames columns, expands final diagnoses of fishkills into separate columns, and condenses final diagnoses into five categories: anthropogenic, infectious, summerkill, winterkill, and unknown. All diagnoses are categorized as above except for 1) "change in temperature", 2) "thermal shock", and 3) all variants of "low 02". These diagnoses are attribued to summerkill or winterkill depending on the time of year, based on the months used in Till (see below). However, note that one "low 02" variant, "low 02, high temp", was already classified as summerkill.
# 1) Winterkill if between Nov and Apr
# 2) Summerkill if between Jun and Sep
# 3) Manually check events in May
mn.fish <- mn.fish %>%
  rename_all(tolower) %>%
  mutate_all(tolower) %>%
  mutate(date = as.Date(with(mn.fish, paste(year, month, day, sep = "-")), "%Y-%m-%d"),
         month = as.numeric(as.character(month))) %>%
  dplyr::filter(date > "2003-01-01", date < "2013-12-31") %>%  # changed to match timespan of Phelps, removed last 6 months
  rename(event = event..,
         waterbody.name = waterbody,
         lat  = y,
         long = x,
         cause.group = final.diagnosis) %>%
  mutate(dummy = 1,
         cause.groups = cause.group) %>%
  spread(as.numeric(cause.groups), dummy, fill = 0) %>%
  rename(unknown = V1) %>% # unknown diagnoses (blank cells) were moved to V1
  mutate(anthropogenic = ifelse(`biofueling bleach` >= 1 | `chemica ` >= 1 | `chemical smell suspected spill` >= 1 | `discharge power plant` >= 1 | `fertilizer spill` >= 1 | `gasoline spill` >= 1 | `glycol release` >= 1 | manure >= 1 | `manure spill` >= 1 | `nuclear plant shutdown` >= 1 | `paper mill` >= 1 | `power plant related` >= 1 | spill >= 1 | `styrene toxicity` >= 1 | `temp fluctuation from plant` >= 1 | `wwtp released` >= 1 | `zebra mussel treatment` >= 1, 1, 0),
         infectious = ifelse(`a.hydrophila intestine+` >= 1 | `bacterial and parasitic infection` >= 1 | `bacterial gill disease` >= 1 | `bacterial septicemia` >= 1 | `bleeding disease?` >= 1 | `carp erythrodermatitis` >= 1 | columnaris >= 1 | `columnaris disease and aermonas septicemia)` >= 1 | `columnaris with parasitic infection` >= 1 | `environmental gill disease` >= 1 | `environmental gill disease with low level of secondary parasitic infection.` >= 1 | `environmental gill disease.  ` >= 1 | `environmental gill disease; systemic bacterial infection due to a. hydrophila, p. fluorescens and external and internal parasitic infections` >= 1 | `gill parasites` >= 1 | `intralamellar henneguya` >= 1 | `opportustic bacterial infection` >= 1 | `parasite infestation and stress` >= 1 | `regressed lymphosarcoma from last year. ` >= 1 | svc >= 1, 1, 0),
         summerkill = ifelse(summerkill >= 1 | `low 02, high temp` >= 1 | `warm temp` >= 1, 1, 0),
         summerkill = ifelse(`low 02` >= 1 | `low 02, stress` >= 1 | `low o2` >= 1 | `change in temperatures` >= 1 | `thermal shock` >= 1 && month >= 6 && month <= 10, 1, 0),
         winterkill = ifelse(winterkill >= 1 | `cold shock` >= 1 | `partial winterkill` >= 1 && month >= 11, 1, 0),
         winterkill = ifelse(winterkill >= 1 | `cold shock` >= 1 | `partial winterkill` >= 1 && month <= 4, 1, winterkill),
         unknown = ifelse(unknown >= 1 | `02 supersaturation` >= 1 | `algal bloom` >= 1 | `environmental factor` >= 1 | pending >= 1 | `possible columnaris` >= 1 | `possible low 02` >= 1 | `possible paint` >= 1 | `possible toxin` >= 1 | stress >= 1 | `suspected disease` >= 1 | u >= 1 | `low water levels, leafs` >= 1 | `environmental stress with columnaris` >= 1, 1, 0),
         unknown = ifelse(anthropogenic == 0 & infectious == 0 & summerkill == 0 & winterkill == 0 & unknown == 0, 1, unknown)) %>%
  dplyr::select(., -c(3, 10, 46:48, 50:99, 101:106, 108:109)) # removes expanded diagnoses from above

# Adds localities of the centroid of waterbodies for events that had a location name but no coordinates These coordinates were found in Google Earth and saved as "data/raw/mme_missing.kml". For transparency, below are each of the events, location names, and coordinates. I was unable to find coordinates for all of the missing locations. The modified MN dataset is exported at the end of these steps to see which do and do not have coordinates. Note that 1) event s2005163 is Rice Lake, Faribault County, but there are 2 Rice Lakes in that county via Google Earth and 2) the coordinates were changed for Long Lake, Otter Tail County.

# pl2003098
# Elk Lake, Grant County, MN
mn.fish$lat[11]  <- c(45.866267)
mn.fish$long[11] <- c(-95.802646)

# s2003062
# Diamond Lake, Hennepin County, MN
mn.fish$lat[35]  <- c(44.900290)
mn.fish$long[35] <- c(-93.269375)

# s2003103
# Madison Lake, Blue Earth County, MN
mn.fish$lat[9]  <- c(44.192717)
mn.fish$long[9] <- c(-93.808331)

# s2003171
# Hallet's Pond, Nicolett County, MN
mn.fish$lat[14]  <- c(44.338106)
mn.fish$long[14] <- c(-93.952646)

# s2003224
# Mink Lake, Wright County, MN
mn.fish$lat[18]  <- c(45.272577)
mn.fish$long[18] <- c(-94.023599)

# s2003231
# Gull Lake, Cass County, MN
mn.fish$lat[21]  <- c(46.456247)
mn.fish$long[21] <- c(-94.334078)

# s2004168
# Round Lake, Becker County, MN
mn.fish$lat[43]  <- c(47.038514)
mn.fish$long[43] <- c(-95.543234)

# s2005114 and s2011077
# Twin Lake, Hennepin County, MN
mn.fish$lat[c(52, 222)]   <- c(45.045690)
mn.fish$long[c(52, 222)]  <- c(-93.340588)

# s2006090
# Washington Lake, Le Suerur County
mn.fish$lat[106]  <- c(44.246514)
mn.fish$long[106] <- c(-93.868075)

# s2006102
# Long Lake, Hennepin County, MN
mn.fish$lat[110]  <- c(44.988472)
mn.fish$long[110] <- c(-93.555642)

# s2009170
# Twin Pond, St. Louis County, MN
mn.fish$lat[201]  <- c(46.778346)
mn.fish$long[201] <- c(-92.123294)

# pl2011248
# Long Lake, Otter Tail County, MN
mn.fish$lat[253]  <- c(46.410217)
mn.fish$long[253] <- c(-95.549014)

# Reformats columns for matching GPS coordinates of locations and waterbody centroids, and removes locations without coordintates because the function that finds the distance between GPS coordinates doesn't work with NAs.
mn.fish <- mn.fish %>%
  mutate(lat  = as.numeric(lat), # NAs are empty cells
         long = as.numeric(long)) %>%
  subset(., !is.na(lat))

# The following associates each set of coordinates with the nearest waterbody centroid. To do this, I subset a unique identifier for event and its coordinates. I match these coordinates with locations in the NHD dataset (site_id), then use the stored unique identifer to add the new coordinates and waterbody information for each event.
mn.fish.gps <- mn.fish %>%
  dplyr::select(., c(1, 7:8)) %>% # saves unique identifer, lat, and long
  .[, c(1, 3, 2)] # reorders lat and long for functions below

# Creates spatial points for event localities and waterbody centroids
mn.fish.sp  <- SpatialPoints(mn.fish.gps[, 2:3])
mn.site.sp  <- SpatialPoints(site.id[, 4:5])

# Finds nearest lake centroid for each event locality
mn.nearest <- apply(gDistance(mn.fish.sp, mn.site.sp, byid = TRUE), 2, which.min)

# Merges event localities and nearest waterbody centroid estimates
mn.fish <- mn.fish.gps %>%
  mutate(site = as.vector(mn.nearest)) %>% # adds nearest waterbody estimates to event localities
  dplyr::select(., -c("lat", "long")) %>% # removes old coordinates
  left_join(., site.id, by = "site", all = TRUE) %>%
  left_join(., mn.fish, by = "event", all = TRUE) %>%
  dplyr::select(., -c("long.y", "lat.y")) %>% # removes old coordinates
  rename(lat  = lat.x,
         long = long.x) %>%
  subset(., !is.na(.$lat)) # removes events without coordinates

# Subsets events that occurred in the same waterbody and month. To ensure that all taxa and causes are accounted for (e.g., different species and/or causes for combined events), I subset which events occurred in unique waterbodies and months (mn.fish.1), and which events occurred in the same waterbodies and months (mn.fish.2). I use the latter to combine duplicate events.

# Events without duplicates
mn.fish.1 <- mn.fish %>% 
  group_by(site_id, year, month) %>% 
  filter(n() == 1) %>%
  arrange(., site_id, year, month)

# Events with duplicates
mn.fish.2 <- mn.fish %>% 
  group_by(site_id, year, month) %>% 
  filter(n() != 1) %>%
  arrange(., site_id, year, month)

# Adds missing values to pl2013155(s2013141)
# Taxa: were all NAs but carp were observed
which(grepl("pl2013155", mn.fish.1$event))
mn.fish.1$centrarchidae[188]  <- c(0)
mn.fish.1$percidae[188]       <- c(0)
mn.fish.1$esocidae[188]       <- c(0)
mn.fish.1$ictaluridae[188]    <- c(0)
mn.fish.1$cyprinidae[188]     <- c(1)
mn.fish.1$salmonidae[188]     <- c(0)
mn.fish.1$osmeridae[188]      <- c(0)
mn.fish.1$catostomidae[188]   <- c(0)
mn.fish.1$sciaenidae[188]     <- c(0)
mn.fish.1$lepisosteidae[188]  <- c(0)

# Removes s2011088; Keeps s2011090
# Causes: two winterkills
# Taxa: different
which(grepl("s2011090", mn.fish.2$event))
mn.fish.2$ictaluridae[2]     <- c(1)
mn.fish.2$bullhead[2]        <- c(1)
mn.fish.2$channel.catfish[2] <- c(1)

# Removes pl2007100 and pl2007101; Keeps pl2007104
# Causes: two unknowns, one infectious = infectious
# Taxa: same

# Removes s2013146; Keeps s2013186
# Causes: one unknown, one infectious = infectious
# Taxa: different

# Removes pl2007098; Keeps pl2007099
# Causes: two unknown
# Taxa: different
which(grepl("pl2007099", mn.fish.2$event))
mn.fish.2$centrarchidae[9] <- c(1)
mn.fish.2$sunfish[9]       <- c(1)

# Removes s2013138; Keeps pl2013162(s2013200)
# Causes: one unknown, one infectious = infectious
# Taxa: different
which(grepl("pl2013162", mn.fish.2$event))
mn.fish.2$crappie[11] <- c(1)

# Removes s2006039; Keeps s2006051
# Causes: two summerkills
# Taxa: different

# Removes pl2007129; Keeps pl2007133
# Causes: two unknowns
# Taxa: same

# Removes pl2005106 and s2005118; Keeps pl2005105
# Causes: two infectious, one unknown = infectious
# Taxa: different

# Removes pl2006111; Keeps s2006073
# Causes: two unknowns
# Taxa: different
which(grepl("s2006073", mn.fish.2$event))
mn.fish.2$crappie[19] <- c(1)

# Removes pl2005150; Keeps pl2005159
# Causes: two unknowns
# Taxa: same

# Removes s2003234; Keeps pl2003150
# Causes: one unknown, one anthropogenic = anthropoogenic
# Taxa: different
which(grepl("pl2003150", mn.fish.2$event))
mn.fish.2$anthropogenic[23] <- c(1)
mn.fish.2$unknown[23]       <- c(0)

# Removes s2011188; Keeps s2011187
# Causes: two unknowns
# Taxa: different
which(grepl("s2011187", mn.fish.2$event))
mn.fish.2$salmonidae[25] <- c(1)
mn.fish.2$whitefish[25]  <- c(1)

# Removes events that were combined above after accounting for different causes and taxa
mn.fish.2 <- mn.fish.2[!(mn.fish.2$event == "s2011188" | mn.fish.2$event == "s2003234" | mn.fish.2$event == "pl2005150" | mn.fish.2$event == "pl2006111" | mn.fish.2$event == "pl2005106" | mn.fish.2$event == "s2005118" | mn.fish.2$event == "pl2007129" | mn.fish.2$event == "s2006039" | mn.fish.2$event == "s2013138" | mn.fish.2$event == "pl2007098" | mn.fish.2$event == "s2013146" | mn.fish.2$event == "pl2007100" | mn.fish.2$event == "pl2007101" | mn.fish.2$event == "s2011088"), ]

# Sums the number of fish families and species for each event. The taxonomic resolution of observations varies, and this code is conservative. It considers all observations that may have been of the same species as a single species (e.g., bass + largemouth bass = 1 species). To do this, I sum the columns of unique species, then use ifelse statements to only add one species for coarse taxonomic categorizations.
mn.fish <- mn.fish.1 %>%
  merge(., mn.fish.2, all = TRUE) %>%
  rename(gizzard.shad = gizzard.gizzard.shad) %>%
  mutate(month = as.numeric(month),
         clupeidae = ifelse(gizzard.shad >= 1, 1, 0)) %>% # add missing family column
  mutate_at(c(13:53), as.numeric) %>% # convert families and species to numeric
  mutate(fish_families = rowSums(.[, c(13:22, 53)], na.rm = TRUE), # sum families
         fish_species  = rowSums(.[, c(23, 27:34 ,38:40, 42:47)], na.rm = TRUE), # sum species (exceptions below)
         fish_species  = ifelse(brown.trout >= 1 | trout >= 1 & !is.na(brown.trout) & !is.na(trout), fish_species + 1, fish_species),
         fish_species  = ifelse(largemouth.bass >= 1 | smallmouth.bass >= 1 | bass >= 1 | crappie >= 1 | sunfish >= 1 & !is.na(largemouth.bass) & !is.na(smallmouth.bass) & !is.na(bass) & !is.na(brown.trout) & !is.na(crappie) & !is.na(sunfish), fish_species + 1, fish_species)) %>%
  mutate_all(na_if, "") %>% # replaces empty cells with NAs
  mutate_at(., vars(c(13:22, 53)), list(~ ifelse(fish_families == 0, NA, .))) %>% # ensures that, if no fish families were observed, NAs are in all the species columns to reduce the number of false negatives
  mutate_at(., vars(c(23, 27:34 ,38:40, 42:47)), list(~ ifelse(fish_species == 0, NA, .))) %>% # ensures that, if no fish species were observed, NAs are in all the families columns to reduce the number of false negatives
  mutate(fish_families = ifelse(fish_families == 0, NA, fish_families))

# Removes unnecessary dataframes
rm(mn.fish.1, mn.fish.2,
   mn.fish.gps, mn.fish.sp,
   mn.site.sp, mn.nearest, wi.site)
```

### Step 3: Add Wisconsin fishkill data

This reformats the WI fishkill dataset. First, this combines fishkills that occurred in the same waterbody and month into a single event as above. All taxa are organized by family and, if possible, species. Second, this associates each fishkill event with the centroid of the nearest waterbody as above. Note that a truncated version of "site_id" is already in the original WI fishkill dataset, but I re-add the full version for consistency with the MN data. Third, this calculates the species and family richness for each fishkill event.

```{r: Add Wisconsin fishkill data}
# Removes fishkill events outside of the study period, renames columns, and expands final diagnoses for fishkills into separate columns
wi.fish <- wi.fish %>%
  mutate(date  = as.Date(wi.fish$Investigation.Start.Date, "%d-%b-%Y"),
         month = month(as.POSIXlt(date, format="%d-%b-%Y")),
         state = "wi") %>%
  rename_all(tolower) %>%
  mutate_all(tolower) %>%
  dplyr::filter(date > "2003-01-01", date < "2013-12-31") %>%  # changed to match timespan of Phelps, removed last 6 months
  rename(#month        = investigation.start.month,
         event        = fishkill.inv.seq.no,
         cause.group  = cause.category.4,
         fish_species = x..fish.species.confirmed) %>%
  mutate(event = as.integer(event),
         dummy = 1,
         cause.groups = cause.group) %>% 
  spread(cause.groups, dummy, fill = 0) %>%
  distinct(waterbody.name, year, month, .keep_all = TRUE) %>%
  rename(anthropogenic = `anthropogenic condition`,
         infectious    = `infectious agent`) %>%
  replace_with_na_all(condition = ~.x == "unknown") %>% # replaces unknowns with NAs
  mutate(acipenseridae = ifelse(sturgeon >= 1, 1, 0),
         amiidae = ifelse(blowfin >= 1 | dogfish >= 1, 1, 0),
         catostomidae = ifelse(bigmouth.buffalo >= 1 | redhorse >= 1 | suckerfish >= 1, 1, 0),
         centrarchidae = ifelse(bass >= 1 | bluegill >= 1 | crappie >= 1 | pumpkinseed >= 1 | sunnies >= 1 | sunfish >= 1, 1, 0),
         cottoidae = ifelse(sculpin >= 1, 1, 0),
         clupeidae = ifelse(gizzard.shad >= 1, 1, 0),
         cyprinidae = ifelse(carp >= 1 | chub >= 1 | dace >= 1 | golden.shiner >= 1 | minnow >= 1, 1, 0),
         esocidae = ifelse(muskies >= 1 | pike >= 1, 1, 0),
         gasterosteidae = ifelse(stickleback >= 1, 1, 0),
         gobiidae = ifelse(round.goby >= 1, 1, 0),
         ictaluridae = ifelse(bullhead >= 1 | catfish >= 1, 1, 0),
         percidae = ifelse(darter >= 1 | perch >= 1 | walleye >= 1, 1, 0),
         salmonidae = ifelse(cisco >= 1 | trout >= 1, 1, 0),
         sciaenidae = ifelse(drum >= 1 | sheapshead >= 1, 1, 0)) %>%
  dplyr::select(., -c(1, 4, 6, 7, 9:11, 13:21, 33, 49, 51, 57:59, 64)) %>% # removes non-fish taxa and unneccessary columns
  merge(., site.id, by = "wbic", all.x = TRUE) %>%
  mutate_at(c(4, 5, 39), as.character) %>% # convert event, month, and year to character
  mutate_at(c(6:37, 46:59), as.numeric) # convert families and species to numeric

# Manually changes values for events where at least one taxa was observed, but there are NAs in the remaining species and family columns. These changes ensure that all entries have either presence or absence (0 or 1) if at least one taxa was documented, and all entries have NAs if no taxa were reported.

# Event: 64
# Row: 552
wi.fish[552, c(6:37, 46:59)][is.na(wi.fish[552, c(6:37, 46:59)])] = 0

# Event: 616
# Row: 132
wi.fish[132, c(6:37, 46:59)][is.na(wi.fish[132, c(6:37, 46:59)])] = 0

# Event: 3321
# Row: 274
wi.fish[274, c(6:37, 46:59)][is.na(wi.fish[274, c(6:37, 46:59)])] = 0

# Event: 3284
# Row: 463
wi.fish[463, c(6:37, 46:59)][is.na(wi.fish[463, c(6:37, 46:59)])] = 0

# Event: 2262
# Row: 302
wi.fish[302, c(6:37, 46:59)][is.na(wi.fish[302, c(6:37, 46:59)])] = 0

# Event: 2259
# Row: 552
wi.fish[200, c(6:37, 46:59)][is.na(wi.fish[200, c(6:37, 46:59)])] = 0

# Event: 2160
# Row: 552
wi.fish[259, c(6:37, 46:59)][is.na(wi.fish[259, c(6:37, 46:59)])] = 0

# Event: 2033
# Row: 552
wi.fish[260, c(6:37, 46:59)][is.na(wi.fish[260, c(6:37, 46:59)])] = 0

# Event: 1722
# Row: 552
wi.fish[194, c(6:37, 46:59)][is.na(wi.fish[194, c(6:37, 46:59)])] = 0

# Event: 1508
# Row: 552
wi.fish[193, c(6:37, 46:59)][is.na(wi.fish[193, c(6:37, 46:59)])] = 0

# Event: 1455
# Row: 552
wi.fish[413, c(6:37, 46:59)][is.na(wi.fish[413, c(6:37, 46:59)])] = 0

# Event: 1399
# Row: 552
wi.fish[206, c(6:37, 46:59)][is.na(wi.fish[206, c(6:37, 46:59)])] = 0

# Event: 1269
# Row: 552
wi.fish[458, c(6:37, 46:59)][is.na(wi.fish[458, c(6:37, 46:59)])] = 0

# Event: 1136
# Row: 552
wi.fish[288, c(6:37, 46:59)][is.na(wi.fish[288, c(6:37, 46:59)])] = 0

# Event: 107
# Row: 552
wi.fish[395, c(6:37, 46:59)][is.na(wi.fish[395, c(6:37, 46:59)])] = 0

# Subsets events that occurred in the same waterbody and month. To ensure that all taxa and causes are accounted for (e.g., different species and/or causes for combined events), I subset which events occurred in unique waterbodies and months (wi.fish.1), and which events occurred in the same waterbodies and months (wi.fish.2). I use the latter to combine duplicate events.

# Subsets events without duplicates (using "wbic" for this because of conflict listed above)
wi.fish.1 <- wi.fish %>% 
  group_by(wbic, year, month) %>% 
  filter(n() == 1) %>%
  arrange(., wbic, year, month)

# Subsets events with duplicates (using "wbic" for this because of conflict listed above)
wi.fish.2 <- wi.fish %>%
  group_by(wbic, year, month) %>% 
  filter(n() != 1) %>%
  arrange(., wbic, year, month)

# Creates columns for the combination of events in the same month and waterbody, and designates which columns (species and family) to combine. This tep ensures that all taxa are accounted for in duplicate events.
wi.columns    = c("wbic", "year", "month")
wi.duplicates = c("sunnies", "bluegill", "crappie",
                  "bass", "bullhead", "suckerfish",
                  "trout", "gizzard.shad", "round.goby",
                  "cisco", "pike", "muskies", "walleye",
                  "carp", "sheapshead", "perch", "catfish",
                  "sculpin", "stickleback", "minnow",
                  "bigmouth.buffalo", "pumpkinseed",
                  "drum", "darter", "dace", "chub",
                  "redhorse", "sunfish", "golden.shiner",
                  "blowfin", "dogfish", "sturgeon",
                  "acipenseridae", "amiidae", "catostomidae",
                  "centrarchidae", "cottoidae", "clupeidae",
                  "cyprinidae", "esocidae", "gasterosteidae",
                  "gobiidae", "ictaluridae", "percidae",
                  "salmonidae", "sciaenidae")

# Sums fish taxa by wbic, year, and month
wi.fish.3 = ddply(wi.fish.2, wi.columns, function(x) colSums(x[wi.duplicates]))

# Changes all sums from above that are greater than 1 (same observation of species or taxa) to 1 (presence)
wi.fish.3 <- wi.fish.3 %>%
  mutate_if(is.numeric, ~1 * (. >= 1))

# Removes old fish taxa counts and adds combined fish taxa counts 
wi.fish.2 <- wi.fish.2 %>%
  dplyr::select(., -c(6:37, 46:59)) %>%
  merge(wi.fish.3, ., by = c("wbic", "month", "year"), all = TRUE)

# Merges dataframe without duplicates (WI.Fish.1) and dataframe with modified (combined taxa counts) duplicates (WI.Fish.2), then sums the number of fish families and species for each event. The taxonomic resolution of observations varies, and this code is conservative. It considers all observations that may have been of the same species as a single species (e.g., bass + largemouth bass = 1 species). To do this, I sum the columns of unique species, then use ifelse statements to only add one species for vague categorizations.
wi.fish <- wi.fish.1 %>%
  merge(., wi.fish.2, all = TRUE) %>%
  mutate(month = as.numeric(month),
         fish_families = rowSums(.[, c(46:59)]), # sum families
         fish_species  = rowSums(.[, c(10:37)]), # sum species (exceptions below)
         fish_species = ifelse(sunnies >= 1 | bluegill >= 1 | crappie >= 1 | bass >= 1 & !is.na(sunnies) & !is.na(bluegill) & !is.na(crappie) & !is.na(bass), fish_species + 1, fish_species)) %>%
  mutate_all(na_if,"") %>% # replaces empty cells with NAs
  mutate_at(., vars(c(46:59)), list(~ ifelse(fish_families == 0, NA, .))) %>% # ensures that, if no fish families were observed, NAs are in all the species columns to reduce the number of false negatives
  mutate_at(., vars(c(10:37)), list(~ ifelse(fish_species == 0, NA, .))) %>% # ensures that, if no fish species were observed, NAs are in all the families columns to reduce the number of false negatives
  mutate(fish_families = ifelse(fish_families == 0, NA, fish_families),
         fish_species  = ifelse(fish_species == 0, NA, fish_species)) %>%
  subset(., !is.na(.$lat)) # removes events without coordinates

# Writes csv of modified WI dataset for Fet to review
#write.csv(wi.fish, "data/raw/wi_fey.csv", row.names = TRUE)

# Removes unnecessary dataframes
rm(wi.fish.1, wi.fish.2, wi.fish.3,
   wi.columns, wi.duplicates)
```

### Step 4: Combine fishkill datasets

This combines the MN and WI fishkill datasets First, this removes all fishkill events that occurred in waterways (e.g., contained "river" or "creek" in the waterbody name). Second, this classifies the observed taxa as cold-, cool- (trans or transitionary), or warm-water designations (Table 2, Lyons et al. 2009). For taxonomic groups with numerous designations, I associated them with the most common designation for that group. Third, this ensures that all fishkill events include presence/absences of taxa (e.g., 0 or 1), and all non-fishkill events include NAs throughout the applicable columns. 

```{r: Combine fishkill datasets}
# Merges MN and WI fishkill data, then categorizes taxa observations into cold-, trans- (cool), and warm-water designations (Table 2; Lyons et al., 2009). For non-species specific observations (e.g., minnow), the temperature designation of most species within the observed group was used. Those particular cases are hashed out below:

# "dace"         -> 6/7 trans
# "chub"         -> 2/3 trans
# "minnows"      -> 3/4 warm
# "darter"       -> 8/9 warm
# "perch"        -> 9/12 warm
# "pike"         -> 1/2 warm/trans
# "suckerfish"   -> 10/12 warm

# Merges MN and WI fishkill data
fish <- mn.fish %>%
  merge(., wi.fish, all = TRUE) %>% # merges MN and WI fishkill data
  .[- grep("creek", .$waterbody.name), ] %>% # removes waterbody names that contain "creek"
  .[- grep("river", .$waterbody.name), ] %>% # removes waterbody names that contain "creek"
  mutate(year      = as.numeric(year),
         cold_temp = ifelse(trout >= 1 | brown.trout >= 1 & !is.na(trout) & !is.na(brown.trout), 1, 0), # Cold in Lyons et al., 2009
         cool_temp = ifelse(northern.pike >= 1 | walleye >= 1 | white.sucker >= 1 | yellow.perch >= 1 | chub >= 1 | dace >= 1 | yellow.perch >= 1 | stickleback >= 1 & !is.na(northern.pike) & !is.na(walleye) & !is.na(white.sucker) & !is.na(yellow.perch) & !is.na(chub) & !is.na(dace) & !is.na(yellow.perch) & !is.na(stickleback), 1, 0), # Trans in Lyons et al., 2019
         warm_temp = ifelse(bullhead >= 1 | largemouth.bass >= 1 | smallmouth.bass >= 1 | channel.catfish >= 1 | freshwater.drum >= 1 | redhorse >= 1 | sunfish >= 1 | bass >= 1 | freshwater.drum >= 1 | stonecat >= 1 | drum >= 1 | rockbass >= 1 | gar >= 1 | gizzard.shad >= 1 | sheapshead >= 1 | catfish >= 1 | bigmouth.buffalo >= 1 | pumpkinseed >= 1 | golden.shiner >= 1 | blowfin >= 1 | dogfish >= 1 | minnow >= 1 | darter >= 1 | perch >= 1 | suckerfish >= 1 | crappie >= 1 & !is.na(bullhead) & !is.na(largemouth.bass) & !is.na(smallmouth.bass) & !is.na(channel.catfish) & !is.na(freshwater.drum) & !is.na(redhorse) & !is.na(sunfish) & !is.na(bass) & !is.na(freshwater.drum) & !is.na(stonecat) & !is.na(drum) & !is.na(rockbass) & !is.na(gar) & !is.na(gizzard.shad) & !is.na(sheapshead) & !is.na(catfish) & !is.na(bigmouth.buffalo) & !is.na(pumpkinseed) & !is.na(golden.shiner) & !is.na(blowfin) & !is.na(dogfish) & !is.na(minnow) & !is.na(darter) & !is.na(perch) & !is.na(suckerfish) & !is.na(crappie), 1, 0), # Warm in Lyons et al., 2019
         unknown_temp = ifelse(cisco >= 1 | rainbow.smelt >= 1 | muskies >= 1 | sauger >= 1 | whitefish >= 1 | sturgeon >= 1 | round.goby >= 1 & !is.na(cisco) & !is.na(rainbow.smelt) & !is.na(muskies) & !is.na(sauger) & !is.na(whitefish) & !is.na(sturgeon) & !is.na(round.goby), 1, 0)) %>%
  dplyr::select(., -c(10, 21:31, 42:76)) %>% # removes fish species
  mutate_at(c(12:29, 31:39), ~replace(., is.na(.), 0)) # replaces NAs with 0s for all species/family observations, temperature categories, and fishkill causes

# Removes unnecessary dataframes
rm(mn.fish, wi.fish)
```

### Step 5: Preliminary map of fishkills

This creates a preliminary map of fishkill events across Minnesota and Wisconsin to visually verify the waterbody centroid method used above. Specifically, it creates one map with the fishkill event localities and another map with the fishkill event and waterbody localities across both states.

```{r: Preliminary map of fishkills}
# Subsets data for a map
fish.map <- fish %>%
  subset(., select = c(lat, long, year, state, event)) %>%
  rename(region = state) %>%
  mutate(lat = as.numeric(lat),
         long = as.numeric(long))
         
# Creates state boundaries
states   <- map_data("state")
states   <- subset(states, region %in% c("minnesota", "wisconsin"))

# Creates county boundaries
counties <- map_data("county")
counties <- subset(counties, region %in% c("minnesota", "wisconsin"))

# Map of fishkill events
ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + 
  coord_fixed(1.3) + 
  geom_polygon(data = counties, aes(x = long, y = lat, alpha = 0.1, group = group), color = "darkgray", fill = "gray", size = 0.5) +
  geom_polygon(data = states, color = "black", fill = NA, size = 1) +
  stat_density2d(data = fish.map, aes(x = long, y = lat, fill = ..level.., alpha = ..level.., group = region), bins = 30, geom = "polygon") +
  geom_point(data = fish.map, aes(x = long, y = lat, group = region),
             color = "black", fill = "red", size = 2, shape = 21) +
  theme_nothing()

# For animated maps, avoid this rabbit hole.
#map.animated <- map + transition_states(Year, transition_length = 2, state_length = 2)
#map.animated

# Map of fishkill events and lake localities across upper midwest. Ignore wonky county/state lines, they can be fixed just not a priority.
ggplot(data = states, mapping = aes(x = long, y = lat)) + 
  coord_fixed(1.3) + 
  geom_polygon(data = counties, aes(x = long, y = lat, alpha = 0.1), color = "darkgray", fill = "gray", size = 0.5) +
  geom_polygon(data = states, color = "black", fill = NA, size = 1) +
  geom_point(data = site.id, aes(x = long, y = lat),
             color = "black", fill = "lightblue", size = 1, shape = 21) +
    geom_point(data = fish.map, aes(x = long, y = lat, group = region),
             color = "black", fill = "red", size = 1, shape = 21) +
  theme_nothing()

# Remove unnecessary dataframes
rm(counties, states, fish.map)
```

### Step 6: Add water temperature to historical dataset

This reformats the historical water temperature data (2003-2013). First, this removes water temperature data that predates the fishkill dataset, then processes annual and monthly data separately for computational efficiency. Second, annual and monthly data are averaged across waterbodies with multiple site_ids. Third, z-scores are calculated for the mean and maximum surface and bottom water temperatures. Fourth, the first PC for maximum surface, mean surface, and maximum bottom temperatures is added as a separate column. These steps mimic those used in Till et al. (2019). These temperature estimates are from Winslow et al. (2017), which used six models (ACCESS, CNRM, GFDL, IPSL, MIROC5, MRIS) from the Coupled Model Intercomparison Project Phase 5 (CMIP5).

- `z-score`:    For each water temperature variable via subtraction of the lake x monthly average then division by the SD.
- `water_pca`:  Single PC for all water temperature data.

```{r: Add water temperature data}
# Reformat water temperature dataset
hist.water <- hist.water %>%
  rename_all(tolower) %>%
  filter(year >= 2003, year <= 2013) %>%
  mutate(year = as.character(year)) %>%
  dplyr::select(-contains("strat"),
                -sthermo_depth_mean)

# Reformat annual water temperature data
hist.water.annual <- hist.water %>%
  dplyr::select(-contains('jas'),
                -starts_with('mean_surf_'),
                -starts_with('mean_bot_'), 
                -starts_with('max_surf_'), 
                -starts_with('max_bot_')) %>%
  group_by(site_id, year) %>% # changed from WBIC in Till et al. (2019) workflow
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  ungroup() %>%
  rename(ice_duration = ice_duration_days,
         schmidt = schmidt_daily_annual_sum,
         variance_after_ice_30 = coef_var_0.30, 
         variance_after_ice_60 = coef_var_30.60, 
         cumulative_above_0 = gdd_wtr_0c,
         cumulative_above_5 = gdd_wtr_5c,
         cumulative_above_10 = gdd_wtr_10c) %>%
  mutate(log_schmidt = log(schmidt + .00001),
         year = as.numeric(year))

# Reformat monthly water temperature data
hist.water.month <- hist.water %>%
  dplyr::select(starts_with('mean_surf_'),
                starts_with('mean_bot_'), 
                starts_with('max_surf_'), 
                starts_with('max_bot_'),
                -contains('jas'),
                year, site_id) %>% # changed from WBIC in Till et al. (2019) workflow
  mutate(uniqueid = 1:n()) %>%
  gather(key = "type", value = "temperature", 
         starts_with('mean_surf_'),
         starts_with('mean_bot_'), 
         starts_with('max_surf_'), 
         starts_with('max_bot_')) %>%
  separate(type, into = c('metric', 'depth', 'month'), sep = '_')  %>%
  unite(metric, metric, depth) %>%
  spread(metric, temperature) %>%
  dplyr::select(-uniqueid) %>%
  group_by(site_id, year, month) %>% # changed from WBIC in Till et al. (2019) workflow
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  ungroup() %>%
  arrange(site_id, year, month) %>% # changed from WBIC in Till et al. (2019) workflow
  mutate(date = ymd(paste(year, month, "15"))) %>%
  filter(date > "2003-01-01", date < "2013-12-31") # changed to match timespan of Phelps et al., (2019); removed 6 months at the end

# Create z-scores
hist.water.month <- hist.water.month %>%
  group_by(site_id, month) %>% # changed from WBIC in Till et al. (2019) workflow
  mutate(max_bot_z   = scale(max_bot), # creates z-scores
         max_surf_z  = scale(max_surf),
         mean_bot_z  = scale(mean_bot),
         mean_surf_z = scale(mean_surf)) %>%
  ungroup() %>%
  mutate(layer_diff      = mean_surf - mean_bot, # creates additional temp/time features
         water_quad_temp = mean_surf^2,
         month = fct_collapse(month,
                              "12" = "dec",
                              "1"  = "jan",
                              "2"  = "feb",
                              "3"  = "mar",
                              "4"  = "apr",
                              "5"  = "may",
                              "6"  = "jun",
                              "7"  = "jul",
                              "8"  = "aug",
                              "9"  = "sep",
                              "10" = "oct",
                              "11" = "nov")) %>%
  mutate(year  = as.numeric(as.character(year)),
         month = as.numeric(as.character(month)))

# Perform PCA to collapse collinear covariates into a single variable
water.pr <- hist.water.month %>%
  dplyr::select(max_surf, mean_surf, mean_bot) %>%
  prcomp(center = TRUE, scale = TRUE)

# Isolate PCA results into separate dataframe
water_pca <- hist.water.month %>%
  dplyr::select(max_surf, mean_surf, mean_bot) %>%
  as.matrix() %*% water.pr$rotation[, 1]

# Change "anti-temperature" to temperature
water_pca <- (water_pca * -1)

# Add PCA results into monthly water temperature data
hist.water.month <- hist.water.month %>%
  add_column(water_pca)

# Merge monthly water temperature data and fishkill data
df.historical <- hist.water.month %>%
  dplyr::select(., -c("date")) %>% # removes date column used for monthly water temperature calculations
  left_join(hist.water.annual, by = c("year", "site_id")) %>%
  merge(., fish, by = c("year", "month", "site_id"), all = TRUE) %>%
  dplyr::select(., -c("site", "wbic", "date")) # removes unnecessary columns

# Remove unnecessary dataframes
rm(hist.water.annual, hist.water.month,
   water.pr, water_pca)
```

### Step 7a: Add air temperature data (NOAA) to historical dataset

This was my first attempt at obtaining recent air temperature data (2003-2014). This dataset includes daily air temperature data for all Minnesota and Wisconsin weather stations from NOAA (https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND). However, there are many missing data for both states, and so I decided to use air temperature estimates from PRISM instead (Step 7b). This is all hashed out for a rainy day. For this particular step, I first merged all air temperature data using BASH. I then reformatted the date columns across datasets and calculated the monthly and annual averages of maximum, mean, and minimum air temperatures. Weather stations were then associated with the nearest waterbody centroid.

```{bash: Add air temperature data}
#cd /Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp/data/raw/temp
#awk 'FNR>1' *.csv > ../air_temp.csv
```

```{r: Add air temperature data}
## Add headers for air temperature dataset
#names(temp.air) <- c("station_id", "station_name", "lat_station", "long_station",
#                     "elevation", "date", "mean_temp", "mean_attributes",
#                     "max_temp", "max_attributes", "min_temp", "min_attributes",
#                     "obs_temp", "obs_attributes")
#
## Remove unnecessary columns
#temp.air[,c("station_name", "elevation", "mean_attributes", "max_attributes",
#            "min_attributes", "obs_temp", "obs_attributes")] <- NULL
#
## Substitute / for - to condense dates
#temp.air$date <- gsub(pattern = "-", replacement = "/", x = temp.air$date)
#
## Split dates into year, month, and day columns
#temp.air[8:10] <- do.call('rbind', strsplit(as.character(temp.air$date), '/', fixed = TRUE))
#
## Add headers for air temperature dataset
#names(temp.air)[8:10] <- c("year", "month", "day")
#
## Reorganize date columns (NOAA used two different date formats; one for rows 1:35865, the other for rows 35966:2462091)
#month <- temp.air$year[1:35865]
#day   <- temp.air$month[1:35865]
#year  <- temp.air$day[1:35865]
#temp.air$year[1:35865]  <- paste0("20", year)
#temp.air$month[1:35865] <- month
#temp.air$day[1:35865]   <- day
#
## Remove unnecessary values
#rm(day, month, year)
#
## Subset data to timespan of interest
#temp.air$date <- paste(temp.air$year, temp.air$month, temp.air$day, sep = "-")
#temp.air$date <- as.Date(temp.air$date, format = "%Y-%m-%d")
#temp.air      <- subset(temp.air, date > "2003-01-01" & date < "2014-05-01")
#
#################################################################################
#
## Remove weather stations that lack data for comparison
##temp.air2 <- na.omit(temp.air)
#
## Group coordinates by station_id
#temp.air.group <- temp.air %>%
#  dplyr::select(station_id, lat_station, long_station) %>%
#  group_by(station_id) %>%
#  summarize(
#    lat_station  = mean(lat_station),
#    long_station = mean(long_station)) %>%
#  ungroup()
#
## Save station identification number (station_id) for later
#temp.station <- temp.air.group[1]
#
## Create spatial points for weather stations and waterbodies
#temp.station.sp  <- SpatialPoints(temp.air.group[, 2:3])
##temp.site.sp     <- SpatialPoints(Site.ID[, 9:10])
#MME$lat          <- as.numeric(MME$lat)
#MME$long         <- as.numeric(MME$long)
#temp.site.sp     <- SpatialPoints(MME[, 2:3])
#
## Find nearest lake centroid for each weather station
##temp.nearest <- apply(gDistance(temp.station.sp, temp.site.sp, byid = TRUE, hausdorff = TRUE), 2, which.min)
##temp.nearest <- gDistance(temp.station.sp, temp.site.sp, byid = TRUE, hausdorff = TRUE)
#temp.nearest <- apply(gDistance(temp.site.sp, temp.station.sp, byid = TRUE, hausdorff = TRUE), 2, which.min)
#
## Merge event number and nearest site_id data
#MME$Site <- as.vector(temp.nearest)
#
## Create Site column
#temp.station$Site <- 1:1250
#
## Merge fishkill event locations and estimated site_id locations
##temp.station <- merge(temp.nearest, Site.ID, by = "Site", all.x = TRUE, all.y = TRUE)
#temp.station <- merge(MME, temp.station, by = "Site", all.x = TRUE, all.y = TRUE)
#temp.station <- subset(temp.station, !is.na(temp.station$site_id))
#
## Reformat annual air temperature data
#air.annual <- temp.air %>%
#  mutate(station_id = as.character(station_id),
#         lat_station = as.numeric(lat_station),
#         long_station = as.numeric(long_station),
#         mean_temp = as.numeric(mean_temp),
#         max_temp = as.numeric(max_temp),
#         min_temp = as.numeric(min_temp),
#         year = as.character(year),
#         month = as.character(month),
#         day = as.character(day)) %>%
#  dplyr::select(mean_temp, max_temp, min_temp, station_id, year) %>%
#  group_by(station_id, year) %>%
#  summarize(
#    mean_temp = mean(mean_temp),
#    max_temp  = mean(max_temp),
#    min_temp  = mean(min_temp)) %>%
#  ungroup()
#  
## Reformat monthly air temperature data
#air.month <- temp.air %>%
#  mutate(station_id = as.character(station_id),
#         lat_station = as.numeric(lat_station),
#         long_station = as.numeric(long_station),
#         mean_temp = as.numeric(mean_temp),
#         max_temp = as.numeric(max_temp),
#         min_temp = as.numeric(min_temp),
#         year = as.character(year),
#         month = as.character(month),
#         day = as.character(day)) %>%
#  dplyr::select(mean_temp, max_temp, min_temp, station_id, month, year) %>%
#  group_by(station_id, year, month) %>%
#  summarize(
#    mean_temp = mean(mean_temp),
#    max_temp  = mean(max_temp),
#    min_temp  = mean(min_temp)) %>%
#  ungroup()
#
## Remove leading zero from months
#air.month$month <- gsub("(^|[^0-9])0+", "\\1", air.month$month, perl = TRUE)
#
## Relabel months
#air.month$month <- ifelse(air.month$month == "12", "dec",
#                           ifelse(air.month$month == "1", "jan",
#                                  ifelse(air.month$month == "2", "feb",
#                                         ifelse(air.month$month == "3", "mar",
#                                                ifelse(air.month$month == "4", "apr",
#                                                       ifelse(air.month$month == "5", "may",
#                                                              ifelse(air.month$month == "6", "jun",
#                                                                     ifelse(air.month$month == "7", "jul",
#                                                                            ifelse(air.month$month == "8", "aug",
#                                                                                   ifelse(air.month$month == "9", "sep",
#                                                                                          ifelse(air.month$month == "10", "oct",
#                                                                                                 ifelse(air.month$month == "11", "nov", "NA"))))))))))))
#
## Group months by season
#air.month <- air.month %>%
#  mutate(season = fct_collapse(month,
#                               "winter" = "dec",
#                               "winter" = "jan",
#                               "winter" = "feb",
#                               "spring" = "mar",
#                               "spring" = "apr",
#                               "spring" = "may",
#                               "summer" = "jun",
#                               "summer" = "jul",
#                               "summer" = "aug",
#                               "fall"   = "sep",
#                               "fall"   = "oct",
#                               "fall"   = "nov"))
#
## Create final monthly air temperature dataset
##air.month <- merge(temp.station, air.month, by = "station_id", all.x = TRUE, all.y = TRUE)
#air.month <- merge(temp.station, air.month, by = c("station_id", "month", "year"), all.x = TRUE, all.y = TRUE)
#air.month <- subset(air.month, !is.na(air.month$station_id))
#
## Create final annual air temperature dataset
##air.annual <- merge(temp.station, air.annual, by = "station_id", all.x = TRUE, all.y = TRUE)
#air.annual <- merge(temp.station, air.annual, by = c("station_id", "month", "year"), all.x = TRUE, all.y = TRUE)
#air.annual <- subset(air.annual, !is.na(air.annual$station_id))
#
## Remove unnecessary columns
#air.month[,c("Site", "Prmnn_I", "GNIS_ID", "GNIS_Nm", "ReachCd",
#                 "FType", "FCode")] <- NULL
#air.annual[,c("Site", "Prmnn_I", "GNIS_ID", "GNIS_Nm", "ReachCd",
#                 "FType", "FCode")] <- NULL
#
# Perform PCA to collapse collinear covariates into a single variable (pca.air)
#air.pr <- air.month %>%
#  dplyr::select(max_temp, mean_temp, min_temp) %>%
#  prcomp(center = TRUE, scale = TRUE)
#
## Isolate PCA results into separate dataframe
#air.pca <- air.month %>%
#  dplyr::select(max_temp, mean_temp, min_temp) %>%
#  as.matrix() %*% air.pr$rotation[,1]
#
## Add PCA results into monthly water temperature data
#air.month <- air.month %>%
#  add_column(air.pca)
#
## Remove unnecessary dataframes
#rm(temp.air, temp.air.group, temp.site.sp, temp.station, temp.station.sp, temp.nearest)
```

### Step 7b: Add air temperature (PRISM) to historical dataset

This reformats historical air temperature data (2003-2013) from PRISM (http://www.prism.oregonstate.edu/explorer/bulk.php). To acquire these data, I exported the coordinates and unique indentifiers for each waterbody (site_id) as "localities.csv". First, because the PRISM interface only works with 500 rows at a time,  I manually split "localities.csv" into separate csv files located at "data/raw/localities/localities_#.csv). The files that were returned from these queries are located at
"data/raw/temp_air/2003_prism/PRISM_tmean_stable_4km_200301_201312_#.csv". Second, I manually merged these files into "data/raw/prism_1.csv" and "data/raw/prism_2.csv". This required two files because Excel doesn't enjoy files with >1,000,000 rows. I will eventually write some BASH code that does the manual steps above.

```{r: Add air temperature data}
# Subset unqiue sites from Winslow et al. (2017)
sites <- subset(hist.water, select = c(site_id)) %>%
  unique(.)

# Subset unique sites from site_id
localities <- subset(site.id, select = c(site_id, lat, long)) %>%
  unique(.)

# Create new unique identifier because PRISM truncates the full site_id
localities$id <- c(1:10774)

# Reorder columns for PRISM. Keep these last steps hashed out unless re-performing the PRISM queries because we need "site_id" instead of the truncated unique identifier.
#localities <- localities[, c(2, 3, 4)]

# Save localities for PRISM
#write.csv(localities, "data/raw/localities.csv", row.names = FALSE)

# Remove empty rows between localities (PRISM default). Note: only works when performed separately, not after joining both.
hist.air.1 <- na.omit(hist.air.1)
hist.air.2 <- na.omit(hist.air.2)

# Merge dataframes and remove old dataframes to save RAM
hist.air <- hist.air.1 %>%
  full_join(., hist.air.2) %>%
  rename_all(tolower) %>%
  mutate_all(tolower) %>%
  rename(id       = name,
         long     = longitude,
         lat      = latitude,
         elev     = elevation..m.,
         precip   = ppt..mm.,
         min_air  = tmin..degrees.c.,
         mean_air = tmean..degrees.c.,
         max_air  = tmax..degrees.c.)

# Create year and month columns from date column
hist.air[10:11] <- do.call('rbind', strsplit(as.character(hist.air$date), '-'))

# Rename and reformat year and month columns
hist.air <- hist.air %>%
  dplyr::select(., -c("date")) %>%
  rename(year  = V10,
         month = V11) %>%
  mutate_if(is.character, as.numeric) %>%
  mutate(id = as.character(id))

# Add coordinates to air temperature estimates
hist.air <- localities %>%
  subset(., select = c(site_id, id)) %>%
  mutate(id = as.character(id)) %>%
  full_join(hist.air, ., by = "id")

# Add air temperature to historical dataframe
df.historical <- df.historical %>%
  dplyr::select(., -c("lat", "long", "state", "county")) %>%
  full_join(hist.air, ., by = c("site_id", "year", "month"))

# Create z-scores
df.historical <- df.historical %>%
  group_by(site_id, month) %>% # changed from WBIC in Till et al. (2019) workflow
  mutate(max_air_z  = scale(max_air), # creates z-scores
         mean_air_z = scale(mean_air),
         min_air_z  = scale(min_air)) %>%
  ungroup() %>%
  mutate(air_quad_temp = mean_air^2)

# Perform PCA to collapse collinear covariates into a single variable (air_pca). For this, I used mean and max air temperature (excluded min air temp) so it matched the PCA of mean and max water temperature
air.pr <- df.historical %>%
  dplyr::select(max_air, mean_air, min_air) %>%
  prcomp(center = TRUE, scale = TRUE)

# Add PCA results into monthly air temperature data
air_pca <- df.historical %>%
  dplyr::select(max_air, mean_air, min_air) %>%
  as.matrix() %*% air.pr$rotation[, 1]

# Add PCA results into monthly water temperature data
df.historical <- df.historical %>%
  add_column(air_pca)

# Remove unnecessary dataframes
rm(hist.water, hist.air,
   hist.air.1, hist.air.2,
   air.pr, air_pca, sites)
```

### Step 8: Add geographic, census, and ecoregion to historical dataset

This adds geographic (county, state), 2010 US census, and ecoregion data to the historical dataset. First, I used the waterbody centroid coordinates to determine the county and state for each locality. Second, I used these geographic identifiers to associate county population estimates (https://www.census.gov/geo/maps-data/data/tiger-data.html). Third, I used the waterbody locatlities to determine which ecoregion polygon they were in. Lastly, I associated each waterbody with a single set of geographic coordinates because there are numerous "site_id" identifiers for a single waterbody.

```{r: Add geographic, census, and ecoregion data}
# Set working directory
setwd("/Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp/data/raw")

# Load census data
census.wi <- readOGR(dsn = path.expand("census_data"), layer = 'tabblock2010_55_pophu')
census.mn <- readOGR(dsn = path.expand("census_data"), layer = 'tabblock2010_27_pophu')

# Reformat WI census data
census.wi <- coordinates(census.wi) %>%
  as.data.frame() %>%
  add_column(population = census.wi@data$POP10) %>%
  rename(lat  = V2,
         long = V1) %>%
  mutate(long_round = round(long, 1),
         lat_round  = round(lat, 1)) %>%
  group_by(long_round, lat_round) %>%
  summarize(population = sum(population)) %>%
  dplyr::select(long_round, lat_round, population)

# Reformat MN census data
census.mn <- coordinates(census.mn) %>%
  as.data.frame() %>%
  add_column(population = census.mn@data$POP10) %>%
  rename(lat  = V2,
         long = V1) %>%
  mutate(long_round = round(long, 1),
         lat_round  = round(lat, 1)) %>%
  group_by(long_round, lat_round) %>%
  summarize(population = sum(population)) %>%
  dplyr::select(long_round, lat_round, population)

# Join census data across states
df.census <- full_join(census.wi, census.mn)

# Add census data
df.historical <- df.historical %>%
  mutate(long_round = round(long, 1),
         lat_round  = round(lat, 1)) %>%
  left_join(df.census, by = c("long_round", "lat_round")) %>%
  dplyr::select(-long_round, -lat_round) %>%
  mutate_at(c("population"), ~replace(., is.na(.), 0))

# Create spatial points
ecoregions.sp <- df.historical %>%
  subset(., select = c("long", "lat")) %>%
  SpatialPoints(.)

# Change projection system
proj4string(ecoregions.sp) <- CRS("+proj=longlat +datum=NAD83")

# Set working directory
setwd("/Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp/")

# Load ecoregions
ecoregions.mn <- readOGR(dsn = path.expand("data/raw/ecoregions/mn_eco_l4"), layer = "mn_eco_l4")
ecoregions.wi <- readOGR(dsn = path.expand("data/raw/ecoregions/wi_eco_l4"), layer = "wi_eco_l4")

# Changes projection system
ecoregions.mn <- spTransform(ecoregions.mn, CRS("+proj=longlat +datum=NAD83"))
ecoregions.wi <- spTransform(ecoregions.wi, CRS("+proj=longlat +datum=NAD83"))

# Determines the ecoregion of each locality
ecoregions.mn <- over(ecoregions.sp, ecoregions.mn)
ecoregions.wi <- over(ecoregions.sp, ecoregions.wi)

# Create unique id
ecoregions.mn$id <- seq(1, nrow(ecoregions.mn))
ecoregions.wi$id <- seq(1, nrow(ecoregions.wi))

# Remove NAs
ecoregions.mn <- na.omit(ecoregions.mn)
ecoregions.wi <- na.omit(ecoregions.wi)

# Merge ecoregions across states
ecoregions <- full_join(ecoregions.mn, ecoregions.wi) %>%
  rename_all(tolower) %>%
  mutate_all(tolower) %>%
  dplyr::select(us_l4code, us_l4name, state_name, id) %>%
  rename(l4_code = us_l4code,
         l4_name = us_l4name,
         state = state_name) %>%
  mutate(id = as.numeric(id))

# Add unique identifier and ecoregions to historical dataframe
df.historical <- df.historical %>%
  mutate(id = as.numeric(seq(1, nrow(df.historical)))) %>%
  left_join(., ecoregions, by = c("id")) %>%
  subset(., !is.na(state)) %>%
  mutate(l3_code = substr(.$l4_code, 1, 2)) %>%
  mutate_at(c(35:61), ~replace(., is.na(.), 0))

# Load spatial data
spatial <- readOGR(dsn = path.expand("data/raw/lake_shapes"), layer = "model_lakes")

# Extract spatial variables
df.spatial <- coordinates(spatial) %>%
  as.data.frame() %>%
  add_column(site_id = as.character(spatial@data$site_id)) %>%
  inner_join(site.id, by = "site_id") %>%
  mutate(V2 = NULL,
         V1 = NULL) %>%
  dplyr::select(lat, long, site_id)

# Represent each waterbody by a single GPS coordinate
df.spatial <- df.spatial %>%
  group_by(site_id) %>%
  summarize(long = mean(long),
            lat  = mean(lat))

# Merge spatial data and add seasons
df.historical <- df.historical %>%
  dplyr::select(., -c("lat", "long")) %>%
  left_join(., df.spatial, by = "site_id") %>%
  mutate(season = ifelse(month == "12" | month == "1" | month == "2", "winter",
                         ifelse(month == "3" | month == "4" | month == "5", "spring",
                                ifelse(month == "6" | month == "7" | month == "8", "summer",
                                       ifelse(month == "9" | month == "10" | month == "11", "fall", NA)))))

# Save historical dataframe
write.csv(df.historical, "data/processed/df_historical.csv", row.names = FALSE)

# Remove unnecessary dataframes
rm(fish, df.historical,
   ecoregions, ecoregions.sp,
   ecoregions.mn, ecoregions.wi,
   localities, spatial)
```

### Step 9: Add water temperature to future dataset

This reformats future water temperature estimates (2041-2059; 2081-2099) via the same methodology used to create the concurrent water temperature dataset. First, this processes annual and monthly data separately for computational efficiency. Second, this averages annual and monthly data across waterbodies with multiple site_ids. Third, z-scores are calculated for the mean and maximum surface and bottom water temperatures. Fourth, the first PC for maximum surface, mean surface, and maximum bottom temperatures is added as a separate column. These temperature estimates are from Winslow et al. (2017), which used six models (ACCESS, CNRM, GFDL, IPSL, MIROC5, MRIS) from the Coupled Model Intercomparison Project Phase 5 (CMIP5) and were based on RCP 8.5 projections.

```{r: Add water temperature}
# Load future water temperature data
future.water <- read_tsv("data/raw/ACCESS_thermal_metrics.tsv") %>%
  inner_join(site.id, by = "site_id")

# Reformat water temperature data
future.water <- future.water %>%
  rename_all(tolower) %>%
  filter(year >= 2013) %>%
  mutate(year = as.character(year)) %>%
  dplyr::select(-contains("strat"),
         -sthermo_depth_mean)

# Create annual data
future.water.annual <- future.water %>%
  dplyr::select(-contains('jas'),
                -starts_with('mean_surf_'),
                -starts_with('mean_bot_'), 
                -starts_with('max_surf_'), 
                -starts_with('max_bot_')) %>%
  group_by(site_id, year) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  ungroup() %>%
  rename(ice_duration = ice_duration_days,
         schmidt = schmidt_daily_annual_sum,
         variance_after_ice_30 = coef_var_0.30, 
         variance_after_ice_60 = coef_var_30.60, 
         cumulative_above_0 = gdd_wtr_0c,
         cumulative_above_5 = gdd_wtr_5c,
         cumulative_above_10 = gdd_wtr_10c) %>%
  mutate(log_schmidt = log(schmidt + .00001),
         year = as.numeric(year))

# Create monthly data
future.water.monthly <- future.water %>%
  dplyr::select(starts_with('mean_surf_'),
                starts_with('mean_bot_'), 
                starts_with('max_surf_'), 
                starts_with('max_bot_'),
                -contains('jas'),
                year, site_id) %>%
  mutate(uniqueid = 1:n()) %>%
  gather(key = "type", value = "temperature", 
         starts_with('mean_surf_'),
         starts_with('mean_bot_'), 
         starts_with('max_surf_'), 
         starts_with('max_bot_')) %>%
  separate(type, into = c('metric', 'depth', 'month'), sep = '_')  %>%
  unite(metric, metric, depth) %>%
  spread(metric, temperature) %>%
 dplyr::select(-uniqueid) %>%
  group_by(site_id, year, month) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  ungroup() %>%
  arrange(site_id, year, month) %>%
  mutate(date = ymd(paste(year, month, "15")),
         month = fct_collapse(month,
                              "12" = "dec",
                              "1"  = "jan",
                              "2"  = "feb",
                              "3"  = "mar",
                              "4"  = "apr",
                              "5"  = "may",
                              "6"  = "jun",
                              "7"  = "jul",
                              "8"  = "aug",
                              "9"  = "sep",
                              "10" = "oct",
                              "11" = "nov")) %>%
  filter(date > "2013-12-31") %>%
  mutate(year  = as.numeric(as.character(year)),
         month = as.numeric(as.character(month)))

 # Reformat monthly data
future.water.monthly <- future.water.monthly %>%
  group_by(site_id, month) %>%
  mutate(max_bot_z   = scale(max_bot),
         max_surf_z  = scale(max_surf),
         mean_bot_z  = scale(mean_bot),
         mean_surf_z = scale(mean_surf)) %>%
  ungroup() %>%
  mutate(layer_diff = mean_surf - mean_bot,
         water_quad_temp = mean_surf^2)

# Perform PCA to collapse collinear covariates into a single variable (water_pca)
water.pr <- future.water.monthly %>%
  dplyr::select(max_surf, mean_surf, mean_bot) %>%
  prcomp(center = TRUE, scale = TRUE)

# Add PCA results into monthly water temperature data
water_pca <- future.water.monthly %>%
  dplyr::select(max_surf, mean_surf, mean_bot) %>%
  as.matrix() %*% water.pr$rotation[,1]

# Change "anti-temperature" to temperature
water_pca <- (water_pca * -1)

# Add PCA results into monthly water temperature data
future.water.monthly <- future.water.monthly %>%
  add_column(water_pca)

# Add spatial data to future water temperature data
df.future <- future.water.monthly %>%
  left_join(future.water.annual, by = c("year", "site_id")) %>%
  dplyr::select(-lat, -long) %>%
  left_join(df.spatial, by = "site_id")

# Remove unneccesary dataframes
rm(water.pr, water_pca, future.water,
   future.water.annual, future.water.monthly)
```

### Step 10: Add air temperature (NOAA) to future dataset

This prepares future air temperature estimates (2041-2059; 2081-2099) from the NOAA GFDL CM3 model (https://gdo-dcp.ucllnl.org/downscaled_cmip_projections/dcpInterface.html). This is one of the models used in Winslow et al., (2017) and contains estimates for each 1/8 degree (~8 km resolution) under RCP 8.5 projections. These datasets include minimum, mean, and maximum air temperature estimates, as well as precipitation estimates for each location. Each of these variables are in a separate file for the two timespans (2041-2059; 2081-2099). First, each file is converted into a workable dataframe and then merged into a single dataframe. Second, because each file contains unique values for the localities and time (e.g., 1, 2, ... n) instead of the actual localiities and time (e.g., lat, long, month, year), I created sequences based on the metadata to acquire the actual localities and time. Third, this merges the future air and water temperature estimates.

```{r: Add air temperature}
# Open netCDF files
air.tas.2041    <- nc_open(filename = "data/raw/temp_air/2041_gfdl_cm3/bcsd5/Extraction_tas.nc", write = TRUE, readunlim = FALSE, verbose = TRUE)
air.tasmax.2041 <- nc_open(filename = "data/raw/temp_air/2041_gfdl_cm3/bcsd5/Extraction_tasmax.nc", write = TRUE, readunlim = FALSE, verbose = TRUE)
air.tasmin.2041 <- nc_open(filename = "data/raw/temp_air/2041_gfdl_cm3/bcsd5/Extraction_tasmin.nc", write = TRUE, readunlim = FALSE, verbose = TRUE)
air.precip.2041 <- nc_open(filename = "data/raw/temp_air/2041_gfdl_cm3/bcsd5/Extraction_pr.nc", write = TRUE, readunlim = FALSE, verbose = TRUE)

# Transform netCDF files to arrays and retrieve attributes (longitude, latitude, time, variable)
air.tas.2041.a    <- ncvar_get(air.tas.2041, attributes(air.tas.2041$var)$names[1])
air.tasmax.2041.a <- ncvar_get(air.tasmax.2041, attributes(air.tasmax.2041$var)$names[1])
air.tasmin.2041.a <- ncvar_get(air.tasmin.2041, attributes(air.tasmin.2041$var)$names[1])
air.precip.2041.a <- ncvar_get(air.precip.2041, attributes(air.precip.2041$var)$names[1])

# Transform arrays to dataframes
air.tas.2041    <- adply(air.tas.2041.a, c(1, 2, 3))
air.tasmax.2041 <- adply(air.tasmax.2041.a, c(1, 2, 3))
air.tasmin.2041 <- adply(air.tasmin.2041.a, c(1, 2, 3))
air.precip.2041 <- adply(air.precip.2041.a, c(1, 2, 3))

# Remove arrays
rm(air.tas.2041.a, air.tasmax.2041.a,
   air.tasmin.2041.a, air.precip.2041.a)

# Mutate 2041 mean air temperature
air.tas.2041 <- air.tas.2041 %>%
  rename(long     = X1,
         lat      = X2,
         year     = X3,
         mean_air = V1) %>%
  mutate(long = as.numeric(long),
         lat  = as.numeric(lat),
         year = as.numeric(year),
         mean_air = as.numeric(mean_air))

# Mutate 2041 min air temperature
air.tasmin.2041 <- air.tasmin.2041 %>%
  rename(long    = X1,
         lat     = X2,
         year    = X3,
         min_air = V1) %>%
  mutate(long = as.numeric(long),
         lat  = as.numeric(lat),
         year = as.numeric(year),
         min_air = as.numeric(min_air))

# Mutate 2041 max air temperature
air.tasmax.2041 <- air.tasmax.2041 %>%
  rename(long    = X1,
         lat     = X2,
         year    = X3,
         max_air = V1) %>%
  mutate(long = as.numeric(long),
         lat  = as.numeric(lat),
         year = as.numeric(year),
         max_air = as.numeric(max_air))

# Mutate 2041 precipitation
air.precip.2041 <- air.precip.2041 %>%
  rename(long   = X1,
         lat    = X2,
         year   = X3,
         precip = V1) %>%
  mutate(long = as.numeric(long),
         lat  = as.numeric(lat),
         year = as.numeric(year),
         precip = as.numeric(precip))

# Merge air temperature data
future.air.2041 <- air.tas.2041 %>%
  left_join(air.tasmin.2041, by = c("long", "lat", "year")) %>%
  left_join(air.tasmax.2041, by = c("long", "lat", "year")) %>%
  left_join(air.precip.2041, by = c("long", "lat", "year"))

# Remove unnecessary dataframes
rm(air.tas.2041, air.tasmax.2041,
   air.tasmin.2041, air.precip.2041)

# Open netCDF files
air.tas.2081    <- nc_open(filename = "data/raw/temp_air/2081_gfdl_cm3/bcsd5/Extraction_tas.nc", write = TRUE, readunlim = FALSE, verbose = TRUE)
air.tasmax.2081 <- nc_open(filename = "data/raw/temp_air/2081_gfdl_cm3/bcsd5/Extraction_tasmax.nc", write = TRUE, readunlim = FALSE, verbose = TRUE)
air.tasmin.2081 <- nc_open(filename = "data/raw/temp_air/2081_gfdl_cm3/bcsd5/Extraction_tasmin.nc", write = TRUE, readunlim = FALSE, verbose = TRUE)
air.precip.2081 <- nc_open(filename = "data/raw/temp_air/2081_gfdl_cm3/bcsd5/Extraction_pr.nc", write = TRUE, readunlim = FALSE, verbose = TRUE)

# Retrieve attributes (Longitude, Latitude, Time)
air.tas.2081.a    <- ncvar_get(air.tas.2081, attributes(air.tas.2081$var)$names[1])
air.tasmax.2081.a <- ncvar_get(air.tasmax.2081, attributes(air.tasmax.2081$var)$names[1])
air.tasmin.2081.a <- ncvar_get(air.tasmin.2081, attributes(air.tasmin.2081$var)$names[1])
air.precip.2081.a <- ncvar_get(air.precip.2081, attributes(air.precip.2081$var)$names[1])

# Transform arrays to dataframes
air.tas.2081    <- adply(air.tas.2081.a, c(1, 2, 3))
air.tasmax.2081 <- adply(air.tasmax.2081.a, c(1, 2, 3))
air.tasmin.2081 <- adply(air.tasmin.2081.a, c(1, 2, 3))
air.precip.2081 <- adply(air.precip.2081.a, c(1, 2, 3))

# Remove unneccessary dataframes
rm(air.tas.2081.a, air.tasmax.2081.a,
   air.tasmin.2081.a, air.precip.2081.a)

# Mutate 2081 mean air temperature
air.tas.2081 <- air.tas.2081 %>%
  rename(long     = X1,
         lat      = X2,
         year     = X3,
         mean_air = V1) %>%
  mutate(long = as.numeric(long),
         lat  = as.numeric(lat),
         year = as.numeric(year),
         mean_air = as.numeric(mean_air))

# Mutate 2081 min air temperature
air.tasmin.2081 <- air.tasmin.2081 %>%
  rename(long      = X1,
         lat       = X2,
         year      = X3,
         min_air = V1) %>%
  mutate(long = as.numeric(long),
         lat  = as.numeric(lat),
         year = as.numeric(year),
         min_air = as.numeric(min_air))

# Mutate 2081 max air temperature
air.tasmax.2081 <- air.tasmax.2081 %>%
  rename(long      = X1,
         lat       = X2,
         year      = X3,
         max_air = V1) %>%
  mutate(long = as.numeric(long),
         lat  = as.numeric(lat),
         year = as.numeric(year),
         max_air = as.numeric(max_air))

# Mutate 2081 precipitation
air.precip.2081 <- air.precip.2081 %>%
  rename(long      = X1,
         lat       = X2,
         year      = X3,
         precip = V1) %>%
  mutate(long = as.numeric(long),
         lat  = as.numeric(lat),
         year = as.numeric(year),
         precip = as.numeric(precip))

# Merge air temperature data
future.air.2081 <- air.tas.2081 %>%
  left_join(air.tasmin.2081, by = c("long", "lat", "year")) %>%
  left_join(air.tasmax.2081, by = c("long", "lat", "year")) %>%
  left_join(air.precip.2081, by = c("long", "lat", "year"))

# Remove unnecessary dataframes
rm(air.tas.2081, air.tasmax.2081,
   air.tasmin.2081, air.precip.2081)

# The future air temperature data includes separate files for variable. In addition, it does not include coordinates or date values; instead, it has sequences of numbers that correspond to the range of coordinates and dates. The ranges from the original query are saved in the metadata, and were used to create sequences that correspond with the correct coordinates and dates. The lengths of each variable are lised under "dim" in the original *.nc file. For the dates, I created a sequence of numbers for the years, along increments of 1/12 for each month (i.e., year.000 = jan; year.083 = feb, etc.). This allowed for a numeric representation of the date, which could be used to extract the year and month of each row.

# Create sequences to replace generic identifiers for location and date variables based on metadata
seq.long  = seq(from = -98.0625, to = -81.0625, length = 137)
seq.lat   = seq(from = 40.9375, to = 50.9375, length = 81)
seq.month = rep(1:12, each = 11097, times = 19)
seq.2041  = rep(2041:2059, each = 133164)
seq.2081  = rep(2081:2099, each = 133164)

# Replace values with sequences for 2041-2059 data
future.air.2041["long"]   <- seq.long
future.air.2041["year"]   <- seq.2041
future.air.2041["month"]  <- seq.month
future.air.2041 <- future.air.2041 %>%
  mutate(lat = ifelse(lat == 1,  seq.lat[1],  lat),
         lat = ifelse(lat == 2,  seq.lat[2],  lat),
         lat = ifelse(lat == 3,  seq.lat[3],  lat),
         lat = ifelse(lat == 4,  seq.lat[4],  lat),
         lat = ifelse(lat == 5,  seq.lat[5],  lat),
         lat = ifelse(lat == 6,  seq.lat[6],  lat),
         lat = ifelse(lat == 7,  seq.lat[7],  lat),
         lat = ifelse(lat == 8,  seq.lat[8],  lat),
         lat = ifelse(lat == 9,  seq.lat[9],  lat),
         lat = ifelse(lat == 10, seq.lat[10], lat),
         lat = ifelse(lat == 11, seq.lat[11], lat),
         lat = ifelse(lat == 12, seq.lat[12], lat),
         lat = ifelse(lat == 13, seq.lat[13], lat),
         lat = ifelse(lat == 14, seq.lat[14], lat),
         lat = ifelse(lat == 15, seq.lat[15], lat),
         lat = ifelse(lat == 16, seq.lat[16], lat),
         lat = ifelse(lat == 17, seq.lat[17], lat),
         lat = ifelse(lat == 18, seq.lat[18], lat),
         lat = ifelse(lat == 19, seq.lat[19], lat),
         lat = ifelse(lat == 20, seq.lat[20], lat),
         lat = ifelse(lat == 21, seq.lat[21], lat),
         lat = ifelse(lat == 22, seq.lat[22], lat),
         lat = ifelse(lat == 23, seq.lat[23], lat),
         lat = ifelse(lat == 24, seq.lat[24], lat),
         lat = ifelse(lat == 25, seq.lat[25], lat),
         lat = ifelse(lat == 26, seq.lat[26], lat),
         lat = ifelse(lat == 27, seq.lat[27], lat),
         lat = ifelse(lat == 28, seq.lat[28], lat),
         lat = ifelse(lat == 29, seq.lat[29], lat),
         lat = ifelse(lat == 30, seq.lat[30], lat),
         lat = ifelse(lat == 31, seq.lat[31], lat),
         lat = ifelse(lat == 32, seq.lat[32], lat),
         lat = ifelse(lat == 33, seq.lat[33], lat),
         lat = ifelse(lat == 34, seq.lat[34], lat),
         lat = ifelse(lat == 35, seq.lat[35], lat),
         lat = ifelse(lat == 36, seq.lat[36], lat),
         lat = ifelse(lat == 37, seq.lat[37], lat),
         lat = ifelse(lat == 38, seq.lat[38], lat),
         lat = ifelse(lat == 39, seq.lat[39], lat),
         lat = ifelse(lat == 40, seq.lat[40], lat),
         lat = ifelse(lat == 41, seq.lat[41], lat),
         lat = ifelse(lat == 42, seq.lat[42], lat),
         lat = ifelse(lat == 43, seq.lat[43], lat),
         lat = ifelse(lat == 44, seq.lat[44], lat),
         lat = ifelse(lat == 45, seq.lat[45], lat),
         lat = ifelse(lat == 46, seq.lat[46], lat),
         lat = ifelse(lat == 47, seq.lat[47], lat),
         lat = ifelse(lat == 48, seq.lat[48], lat),
         lat = ifelse(lat == 49, seq.lat[49], lat),
         lat = ifelse(lat == 50, seq.lat[50], lat),
         lat = ifelse(lat == 51, seq.lat[51], lat),
         lat = ifelse(lat == 52, seq.lat[52], lat),
         lat = ifelse(lat == 53, seq.lat[53], lat),
         lat = ifelse(lat == 54, seq.lat[54], lat),
         lat = ifelse(lat == 55, seq.lat[55], lat),
         lat = ifelse(lat == 56, seq.lat[56], lat),
         lat = ifelse(lat == 57, seq.lat[57], lat),
         lat = ifelse(lat == 58, seq.lat[58], lat),
         lat = ifelse(lat == 59, seq.lat[59], lat),
         lat = ifelse(lat == 60, seq.lat[60], lat),
         lat = ifelse(lat == 61, seq.lat[61], lat),
         lat = ifelse(lat == 62, seq.lat[62], lat),
         lat = ifelse(lat == 63, seq.lat[63], lat),
         lat = ifelse(lat == 64, seq.lat[64], lat),
         lat = ifelse(lat == 65, seq.lat[65], lat),
         lat = ifelse(lat == 66, seq.lat[66], lat),
         lat = ifelse(lat == 67, seq.lat[67], lat),
         lat = ifelse(lat == 68, seq.lat[68], lat),
         lat = ifelse(lat == 69, seq.lat[69], lat),
         lat = ifelse(lat == 70, seq.lat[70], lat),
         lat = ifelse(lat == 71, seq.lat[71], lat),
         lat = ifelse(lat == 72, seq.lat[72], lat),
         lat = ifelse(lat == 73, seq.lat[73], lat),
         lat = ifelse(lat == 74, seq.lat[74], lat),
         lat = ifelse(lat == 75, seq.lat[75], lat),
         lat = ifelse(lat == 76, seq.lat[76], lat),
         lat = ifelse(lat == 77, seq.lat[77], lat),
         lat = ifelse(lat == 78, seq.lat[78], lat),
         lat = ifelse(lat == 79, seq.lat[79], lat),
         lat = ifelse(lat == 80, seq.lat[80], lat),
         lat = ifelse(lat == 81, seq.lat[81], lat))

# Replace values with sequences for 2081-2099 data
future.air.2081["long"]   <- seq.long
future.air.2081["year"]   <- seq.2081
future.air.2081["month"]  <- seq.month
future.air.2081 <- future.air.2081 %>%
  mutate(lat = ifelse(lat == 1,  seq.lat[1],  lat),
         lat = ifelse(lat == 2,  seq.lat[2],  lat),
         lat = ifelse(lat == 3,  seq.lat[3],  lat),
         lat = ifelse(lat == 4,  seq.lat[4],  lat),
         lat = ifelse(lat == 5,  seq.lat[5],  lat),
         lat = ifelse(lat == 6,  seq.lat[6],  lat),
         lat = ifelse(lat == 7,  seq.lat[7],  lat),
         lat = ifelse(lat == 8,  seq.lat[8],  lat),
         lat = ifelse(lat == 9,  seq.lat[9],  lat),
         lat = ifelse(lat == 10, seq.lat[10], lat),
         lat = ifelse(lat == 11, seq.lat[11], lat),
         lat = ifelse(lat == 12, seq.lat[12], lat),
         lat = ifelse(lat == 13, seq.lat[13], lat),
         lat = ifelse(lat == 14, seq.lat[14], lat),
         lat = ifelse(lat == 15, seq.lat[15], lat),
         lat = ifelse(lat == 16, seq.lat[16], lat),
         lat = ifelse(lat == 17, seq.lat[17], lat),
         lat = ifelse(lat == 18, seq.lat[18], lat),
         lat = ifelse(lat == 19, seq.lat[19], lat),
         lat = ifelse(lat == 20, seq.lat[20], lat),
         lat = ifelse(lat == 21, seq.lat[21], lat),
         lat = ifelse(lat == 22, seq.lat[22], lat),
         lat = ifelse(lat == 23, seq.lat[23], lat),
         lat = ifelse(lat == 24, seq.lat[24], lat),
         lat = ifelse(lat == 25, seq.lat[25], lat),
         lat = ifelse(lat == 26, seq.lat[26], lat),
         lat = ifelse(lat == 27, seq.lat[27], lat),
         lat = ifelse(lat == 28, seq.lat[28], lat),
         lat = ifelse(lat == 29, seq.lat[29], lat),
         lat = ifelse(lat == 30, seq.lat[30], lat),
         lat = ifelse(lat == 31, seq.lat[31], lat),
         lat = ifelse(lat == 32, seq.lat[32], lat),
         lat = ifelse(lat == 33, seq.lat[33], lat),
         lat = ifelse(lat == 34, seq.lat[34], lat),
         lat = ifelse(lat == 35, seq.lat[35], lat),
         lat = ifelse(lat == 36, seq.lat[36], lat),
         lat = ifelse(lat == 37, seq.lat[37], lat),
         lat = ifelse(lat == 38, seq.lat[38], lat),
         lat = ifelse(lat == 39, seq.lat[39], lat),
         lat = ifelse(lat == 40, seq.lat[40], lat),
         lat = ifelse(lat == 41, seq.lat[41], lat),
         lat = ifelse(lat == 42, seq.lat[42], lat),
         lat = ifelse(lat == 43, seq.lat[43], lat),
         lat = ifelse(lat == 44, seq.lat[44], lat),
         lat = ifelse(lat == 45, seq.lat[45], lat),
         lat = ifelse(lat == 46, seq.lat[46], lat),
         lat = ifelse(lat == 47, seq.lat[47], lat),
         lat = ifelse(lat == 48, seq.lat[48], lat),
         lat = ifelse(lat == 49, seq.lat[49], lat),
         lat = ifelse(lat == 50, seq.lat[50], lat),
         lat = ifelse(lat == 51, seq.lat[51], lat),
         lat = ifelse(lat == 52, seq.lat[52], lat),
         lat = ifelse(lat == 53, seq.lat[53], lat),
         lat = ifelse(lat == 54, seq.lat[54], lat),
         lat = ifelse(lat == 55, seq.lat[55], lat),
         lat = ifelse(lat == 56, seq.lat[56], lat),
         lat = ifelse(lat == 57, seq.lat[57], lat),
         lat = ifelse(lat == 58, seq.lat[58], lat),
         lat = ifelse(lat == 59, seq.lat[59], lat),
         lat = ifelse(lat == 60, seq.lat[60], lat),
         lat = ifelse(lat == 61, seq.lat[61], lat),
         lat = ifelse(lat == 62, seq.lat[62], lat),
         lat = ifelse(lat == 63, seq.lat[63], lat),
         lat = ifelse(lat == 64, seq.lat[64], lat),
         lat = ifelse(lat == 65, seq.lat[65], lat),
         lat = ifelse(lat == 66, seq.lat[66], lat),
         lat = ifelse(lat == 67, seq.lat[67], lat),
         lat = ifelse(lat == 68, seq.lat[68], lat),
         lat = ifelse(lat == 69, seq.lat[69], lat),
         lat = ifelse(lat == 70, seq.lat[70], lat),
         lat = ifelse(lat == 71, seq.lat[71], lat),
         lat = ifelse(lat == 72, seq.lat[72], lat),
         lat = ifelse(lat == 73, seq.lat[73], lat),
         lat = ifelse(lat == 74, seq.lat[74], lat),
         lat = ifelse(lat == 75, seq.lat[75], lat),
         lat = ifelse(lat == 76, seq.lat[76], lat),
         lat = ifelse(lat == 77, seq.lat[77], lat),
         lat = ifelse(lat == 78, seq.lat[78], lat),
         lat = ifelse(lat == 79, seq.lat[79], lat),
         lat = ifelse(lat == 80, seq.lat[80], lat),
         lat = ifelse(lat == 81, seq.lat[81], lat))

# Merge future air temperature data
future.air <- future.air.2041 %>%
  rbind(., future.air.2081) %>%
  mutate(year  = as.numeric(year),
         month = as.numeric(month))

# Remove unnecessary dataframes
rm(seq.2041, seq.2081, seq.month, seq.lat, seq.long,
   future.air.2041, future.air.2081)

# Subset unique localities for computational efficiency when associating with waterbodies
localities <- future.air %>%
  subset(., select = c("lat", "long")) %>%
  distinct(.data = .) %>%
  mutate(id = c(1:11097)) # create unique identifier

# Create spatial points for air temperature and waterbody locations (lat, long)
localities.sp <- SpatialPoints(localities[, 1:2])
site.sp       <- SpatialPoints(site.id[, 4:5])

# Find nearest air temperature location for each waterbody
air.nearest <- apply(gDistance(site.sp, localities.sp, byid = TRUE), 2, which.min)

# Add unique identifier to air temperature data
future.air <- future.air %>%
  left_join(localities, by = c("lat", "long")) %>%
  mutate(year  = as.numeric(year),
         month = as.numeric(month))

# Add unique identifier to site.id
site.id$id <- as.vector(air.nearest)

# Add location of nearest air temperature estimate to each waterbody and add water temperature data
df.future <- df.future %>%
  left_join(site.id[,c("site", "id")], by = "site") %>%
  mutate(year  = as.numeric(year),
         month = as.numeric(month)) %>% ####
  left_join(future.air[,c("mean_air", "min_air", "max_air",
                          "precip", "year", "month", "id")],
            by = c("year", "month", "id")) %>%
  mutate(id = NULL) # remove temporary unique identifier

# Create z-scores
df.future <- df.future %>%
  group_by(site_id, month) %>% # changed from WBIC in Till et al. (2019) workflow
  mutate(max_air_z  = scale(max_air), # creates z-scores
         mean_air_z = scale(mean_air),
         min_air_z  = scale(min_air)) %>%
  ungroup() %>%
  mutate(air_quad_temp = mean_air^2) %>%
  subset(., !is.na(mean_air)) %>% # remove rows with missing air temp data
  subset(., !is.na(min_air)) %>%
  subset(., !is.na(max_air))

# Perform PCA to collapse collinear covariates into a single variable (air_pca). For this, I only used mean and max air temperature (excluded min air temp) so it matched the PCA of mean and max water temperature
air.pr <- df.future %>%
  dplyr::select(max_air, mean_air, min_air) %>%
  prcomp(center = TRUE, scale = TRUE)

# Add PCA results into monthly air temperature data
air_pca <- df.future %>%
  dplyr::select(max_air, mean_air, min_air) %>%
  as.matrix() %*% air.pr$rotation[,1]

# Add PCA results into monthly water temperature data
df.future <- df.future %>%
  add_column(air_pca)

# Remove unnecessary dataframes
rm(future.air, site.sp,
   localities, localities.sp,
   air.nearest, air.pr, air_pca)
```

### Step 11: Add geographic, census, and ecoregion to future dataset
This adds geographic (county, state), 2010 US census, and ecoregion data to the historical dataset. First, I used the waterbody centroid coordinates to determine the county and state for each locality. Second, I used these geographic identifiers to associate county population estimates (https://www.census.gov/geo/maps-data/data/tiger-data.html). Third, I used the waterbody locatlities to determine which ecoregion polygon they were in. into the dataset. Lastly, I associated each waterbody with a single set of geographic coordinates because there are numerous "site_id" identifiers for a single waterbody.

This adds geographic (county, state), 2010 US census, and ecoregion data to the future dataset. First, I used the waterbody centroid coordinates to determine the county and state for each locality. Second, I used these geographic identifiers to associate county population estimates (https://www.census.gov/geo/maps-data/data/tiger-data.html). Third, I used the waterbody locatlities to determine which ecoregion polygon they were in. Lastly, I associated each waterbody with a single set of geographic coordinates because there are numerous "site_id" identifiers for a single waterbody.

```{r: Add spatial data}
# Set working directory
setwd("/Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp/data/raw")

# Load census data
census.wi <- readOGR(dsn = path.expand("census_data"), layer = 'tabblock2010_55_pophu')
census.mn <- readOGR(dsn = path.expand("census_data"), layer = 'tabblock2010_27_pophu')

# Reformat WI census data
census.wi <- coordinates(census.wi) %>%
  as.data.frame() %>%
  add_column(population = census.wi@data$POP10) %>%
  rename(lat  = V2,
         long = V1) %>%
  mutate(long_round = round(long, 1),
         lat_round  = round(lat, 1)) %>%
  group_by(long_round, lat_round) %>%
  summarize(population = sum(population)) %>%
  dplyr::select(long_round, lat_round, population)

# Reformat MN census data
census.mn <- coordinates(census.mn) %>%
  as.data.frame() %>%
  add_column(population = census.mn@data$POP10) %>%
  rename(lat  = V2,
         long = V1) %>%
  mutate(long_round = round(long, 1),
         lat_round  = round(lat, 1)) %>%
  group_by(long_round, lat_round) %>%
  summarize(population = sum(population)) %>%
  dplyr::select(long_round, lat_round, population)

# Join census data across states
df.census <- full_join(census.wi, census.mn)

# Add census data
df.future <- df.future %>%
  mutate(long_round = round(long, 1),
         lat_round  = round(lat, 1)) %>%
  left_join(df.census, by = c("long_round", "lat_round")) %>%
  dplyr::select(-long_round, -lat_round) %>%
  mutate_at(c("population"), ~replace(., is.na(.), 0))

# Create spatial points
ecoregions.sp <- df.future %>%
  subset(., select = c("long", "lat")) %>%
  SpatialPoints(.)

# Add projection system
proj4string(ecoregions.sp) <- CRS("+proj=longlat +datum=NAD83")

# Set working directory
setwd("/Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp/")

# Load ecoregions
ecoregions.mn <- readOGR(dsn = path.expand("data/raw/ecoregions/mn_eco_l4"), layer = "mn_eco_l4")
ecoregions.wi <- readOGR(dsn = path.expand("data/raw/ecoregions/wi_eco_l4"), layer = "wi_eco_l4")

# Changes projection system
ecoregions.mn <- spTransform(ecoregions.mn, CRS("+proj=longlat +datum=NAD83"))
ecoregions.wi <- spTransform(ecoregions.wi, CRS("+proj=longlat +datum=NAD83"))

# Determines the ecoregion of each locality
ecoregions.mn <- over(ecoregions.sp, ecoregions.mn)
ecoregions.wi <- over(ecoregions.sp, ecoregions.wi)

# Create unique id
ecoregions.mn$id <- seq(1, nrow(ecoregions.mn))
ecoregions.wi$id <- seq(1, nrow(ecoregions.wi))

# Remove NAs
ecoregions.mn <- na.omit(ecoregions.mn)
ecoregions.wi <- na.omit(ecoregions.wi)

# Merge ecoregions across states
ecoregions <- full_join(ecoregions.mn, ecoregions.wi) %>%
  rename_all(tolower) %>%
  mutate_all(tolower) %>%
  dplyr::select(us_l4code, us_l4name, state_name, id) %>%
  rename(l4_code = us_l4code,
         l4_name = us_l4name,
         state   = state_name) %>%
  mutate(id = as.numeric(id))

# Add unique identifier and ecoregions to historical dataframe
df.future <- df.future %>%
  mutate(id = as.numeric(seq(1, nrow(df.future)))) %>%
  left_join(., ecoregions, by = c("id")) %>%
  subset(., !is.na(state)) %>%
  dplyr::select(., -c("site")) %>%
  mutate(l3_code = substr(.$l4_code, 1, 2),
         season = ifelse(month == "12" | month == "1" | month == "2", "winter",
                         ifelse(month == "3" | month == "4" | month == "5", "spring",
                                ifelse(month == "6" | month == "7" | month == "8", "summer",
                                       ifelse(month == "9" | month == "10" | month == "11", "fall", NA)))))

# Merge spatial data
df.future <- df.future %>%
  dplyr::select(., -c("lat", "long")) %>%
  left_join(., df.spatial, by = "site_id")

# Save historical dataframe
write.csv(df.future, "data/processed/df_future.csv", row.names = FALSE)

# Remove unnecessary dataframes
rm(ecoregions, ecoregions.sp,
   ecoregions.mn, ecoregions.wi,
   census.mn, census.wi, df.census, census,
   site.id, df.spatial, df.future)
```

### Step 11: Add snowfall data

This creates a snowfall dataset for the entire geographic range of the Winslow et al. (2017) dataset, which encompasses WI, MN, and MI. After performing this step, the historical (2003-2014) and future (2041-2059; 2081-2099) datasets are ready for modeling.

```{r: Add snowfall data}
# Create snowfall function
tidy_snow <- function(path) {
  
  e <- extent(-96.8, -83.0, 41.7 , 48.8) # changed to cover the full spatial extent of Winslow et al. (2017)
  a <- crop(raster(path),e)
  
  a1 <- as.data.frame(coordinates(a))
  a2 <- as.data.frame(a)
  
  data <- na.omit(cbind(a1, a2)) 
   
  names(data) <- c('x', 'y', 'snow')

  data$long_round <- round(data$x, 1)
  data$lat_round  <- round(data$y, 1)  

  data_output <- data %>%
    group_by(long_round, lat_round) %>%
    summarise(snow = mean(snow))
    
  data_output$year  <- str_sub(path, 24, 27)
  data_output$month <- str_sub(path, 28, 29)
  return(data_output)
}

# Change working directory
setwd("data/raw/PRISM_precip")

# Save names of PRISM files
file_names <- list.files() %>%
  str_subset("asc$")

# Run tidy_snow function for all PRISM files
df.snow <- map_df(file_names, tidy_snow)

# Change working directory
setwd("/Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp")

# Save processed data
write_csv(df.snow, "data/processed/df_snow.csv")

# Remove unneccessary dataframes
rm(file_names, df.snow, tidy_snow)
```

######################################
Proceed to `02_prepare_models.Rmd`
######################################
