---
title: "Combine datasets"
author: "Mass mortality crew"
date: "2020/05/18"
output: github_document
---

### Background
This document combines Wisconsin and Minnesota fishkill data from Till et al. (2019) and Phelps et al. (2019) datasets. The Till dataset had fishkill events associated with unique identifiers for Wisconsin waterbodies (WBIC) and the Phelps dataset had GPS coordinates for each waterbody in Minnesota. I associated each waterbody with the same unique identifier (site_id), which can be used for comparisons with water temperature data in Winslow et al. (2017). The combined dataset includes all fishkill events from Till et al. (2019) and 240/284 fishkill events from Phelps et al. (2019). 

### Files in data/raw:
- `MN_Fish_Final.csv`: Minnesota fishkill data from Phelps et al. (2019)
- `MN_Site_County.csv`: List of waterbodies in Minnesota from the Minnesota Department of Natural Resources
- `WI_Fish_Final.csv`: Wisconsin fishkill data from Till et al. (2019)
- `WI_Site.csv`: List of waterbodies in Wisconsin from the Wisconsin Department of Natural Resources
- `Site_ID`: Attributes of waterbodies in Minnesota from the Minnesota Department of Natural Resources
- `temp_water.csv`: Historical thermal data for upper midwest lakes (1980 to 2013) from Winslow et al. (2017)
- `PRISM.csv`: Monthly air temperature data from PRISM (http://prism.oregonstate.edu)

### Step 1: Load packages and data

For these procedures, all data are located in the `data/raw` subdirectory. All R packages are loaded normally except for `lakeattribute`, which requires a remote install.

```{r: Load packages and data}
# Install packages
#install.packages(c("plyr", "remotes", "data.table", "tidyverse",
#                   "sp", "rgeos", "sf", "ggmap", "ggspatial", "rgdal",
#                   "lubridate", "raster", "naniar", "compareDF", "maps", "ggplot2"))
#remotes::install_github("USGS-R/lakeattributes")

# Load packages
library(plyr)
library(remotes)
library(lakeattributes)
library(data.table)
library(tidyverse)
library(sp)
library(rgeos)
library(sf)
library(ggmap)
library(ggspatial)
library(rgdal)
library(lubridate)
library(raster)
library(naniar)
library(compareDF)
library(maps)
library(ggplot2)

# Reset global environment
rm(list=ls())

# Set working directory
setwd("/Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp")

# Load files
MN.Fish     <- read.csv(file = "data/raw/MN_Fish_Final.csv", head = TRUE, sep = ",")
MN.Site     <- read.csv(file = "data/raw/MN_Site_County.csv", head = TRUE, sep = ",")
WI.Fish     <- read.csv(file = "data/raw/WI_Fish_Final.csv", head = TRUE, sep = ",")
WI.Site     <- read.csv(file = "data/raw/WI_Site.csv", head = TRUE, sep = ",")
Site.ID     <- read.csv(file = "data/raw/Site_ID.csv", head = TRUE, sep = ",")
temp.water  <- read.csv(file = "data/raw/temp_water.csv")
temp.water  <- inner_join(temp.water, Site.ID, by = "site_id")
air.month   <- read.csv(file = "data/raw/PRISM.csv", head = TRUE, sep = ",")

```

### Step 2: Minnesota fishkills

This matches the GPS coordinates from each fishkill event from Phelps et al. (2019) with the centroid of the nearest waterbody. This allows for the association of each fishkilll event with a "site_id" waterbody identifier.

```{r: Minnesota fishkills}
# Subset event number and coordinates from MN.Fish data
MN.Fish.GPS     <- MN.Fish[, c(1, 70:71)]
MN.Fish.GPS$Lat <- as.numeric(as.character(MN.Fish.GPS$Lat))

# Subset events with coordinates (240 /284 events)
MN.Fish.GPS.1 <- na.omit(MN.Fish.GPS)

# Create list of events without coordinates to manually verify (44 events)
MN.Fish.Comp <- compare_df(MN.Fish.GPS, MN.Fish.GPS.1, c("Event"))
MN.Fish.Comp <- MN.Fish.Comp$comparison_df[1]
MN.Fish.Comp <- inner_join(x = MN.Fish.Comp, y = MN.Fish, by = "Event")

# Save event order for later
MN.Fish.Events <- MN.Fish.GPS.1[, 1]

# Create spatial points
MN.Fish.SP  <- SpatialPoints(MN.Fish.GPS.1[, 2:3])
MN.Site.SP  <- SpatialPoints(Site.ID[, 9:10])

# Find nearest lake centroid for each event
MN.Nearest <- apply(gDistance(MN.Fish.SP, MN.Site.SP, byid = TRUE), 2, which.min)

# Merge event number and nearest site_id data
MN.Fish.GPS.1$Event <- as.vector(MN.Fish.Events)
MN.Fish.GPS.1$Site  <- as.vector(MN.Nearest)

# Merge fishkill event locations and estimated site_id locations
MN.Fish.1 <- merge(MN.Fish.GPS.1, Site.ID, by = "Site", all.x = TRUE, all.y = TRUE)
MN.Fish.1 <- subset(MN.Fish.1, !is.na(MN.Fish.1$Event))

# Create final MN database
MN.Fish.Final <- merge(MN.Fish.1, MN.Fish, by = "Event", all.x = TRUE, all.y = TRUE)
MN.Fish.Final <- subset(MN.Fish.Final, !is.na(MN.Fish.Final$Site))

# Change site_id column to match Till workflow
MN.Fish.Final$Station.Name <- MN.Fish.Final$GNIS_Nm

# Rename columns to match WI data
colnames(MN.Fish.Final)[c(12:13)] <- c("Lat", "Long")

# Save original (OG) GPS points, in case we want those later
colnames(MN.Fish.Final)[c(82:83)] <- c("Lat_OG", "Long_OG")
MN.Fish.Final$Lat_OG              <- as.numeric(as.character(MN.Fish.Final$Lat_OG))

# Remove unnecessary columns
MN.Fish.Final[,c("Site", "Lat.x", "Long.x", "Prmnn_I",
                 "GNIS_ID", "GNIS_Nm", "ReachCd",
                 "FType", "FCode", "GPS", "Notes")] <- NULL

# Remove unnecessary dataframes
rm(MN.Fish, MN.Fish.1, MN.Fish.Comp,
   MN.Fish.GPS, MN.Fish.GPS.1,
   MN.Fish.SP, MN.Site, MN.Site.SP,
   MN.Fish.Events, MN.Nearest)
```

### Step 3: Wisconsin fishkills

This matches unique identifiers for Wisconsin waterbodies (WBIC) from Till et al. (2019) with waterbody information from the Wisconsin Department of Natural Resources. This allows for the association of both Minnesota and Wisconsin fishill events by the same unqiue waterbody identifier (site_id).

```{r: Wisconsin fishkills}
# Merge WI site data and NHD information
WI.Fish.1 <- merge(WI.Site, Site.ID, by = "site_id", all.x = FALSE, all.y = TRUE)

# Merge WI site data and Till et al. (2019) dataset
WI.Fish.2 <- merge(WI.Fish.1, WI.Fish, by = "WBIC", all.x = FALSE, all.y = TRUE)

# Remove sites without data (none removed)
WI.Fish.Final <- subset(WI.Fish.2, !is.na(WI.Fish.2$Event))

# Remove unnecessary columns
WI.Fish.Final[,c("X", "Site", "Prmnn_I", "GNIS_ID",
                 "GNIS_Nm", "ReachCd", "FType", "FCode",
                 "Snail", "Crayfish", "Frogs")] <- NULL

# Remove unnecessary dataframes
rm(WI.Fish, WI.Fish.1, WI.Fish.2, WI.Site)
```

### Step 4: Merge fishkill datasets

This merges the Minnesota and Wisconsin datasets, fixes some formatting issues, and orders the events by date.

```{r: Merge fishkill datasets}
# Merge datasets
Fish.Final <- merge(MN.Fish.Final, WI.Fish.Final, all.x = TRUE, all.y = TRUE)

# Remove unnecessary columns
Fish.Final[,c("Site.Seq.No", "Swims.Station.Id", "Stream.Miles.or.Lake.Acres.Affected",
              "Snail", "Crayfish", "Frogs", "Event", "Lat_OG", "Long_OG", "Fish.Species")] <- NULL

# Order events by date and add sequence of events to remove duplicate events in Step 6
Fish.Final <- Fish.Final[order(as.Date(Fish.Final$Investigation.Start.Date, format="%d-%b-%y")),]

# Create column with order of fishkill events by date
Fish.Final$Fishkill.Inv.Seq.No <- c(1:871)

# Reorder columns for easier comparions
Fish.Final <- Fish.Final[, c(10, 1, 9, 8, 7, 5, 6, 2, 3, 11:68)]

# Remove unnecessary dataframes
rm(MN.Fish.Final, WI.Fish.Final)
```

### Step 5: Group species observations by family

This reformats common names across datasets then groups species observations by taxonomic family.

```{r: Taxonomic organization}
# Create columns for fish families
Fish.Final$Acipenseridae  <- ifelse(Fish.Final$Sturgeon == 1, 1, 0)

Fish.Final$Amiidae        <- ifelse(Fish.Final$Bowfin == 1, 1,
                               ifelse(Fish.Final$Dogfish == 1, 1, 0))

Fish.Final$Catostomidae   <- ifelse(Fish.Final$Bigmouth.Buffalo == 1, 1,
                               ifelse(Fish.Final$Shorthead.Redhorse == 1, 1,
                                      ifelse(Fish.Final$Suckerfish == 1, 1,
                                             ifelse(Fish.Final$White.Sucker == 1, 1, 0))))

Fish.Final$Centrarchidae  <- ifelse(Fish.Final$Bass == 1, 1,
                               ifelse(Fish.Final$Bluegill == 1, 1,
                                      ifelse(Fish.Final$Crappie == 1, 1,
                                             ifelse(Fish.Final$Largemouth.Bass == 1, 1,
                                                    ifelse(Fish.Final$Pumpkinseed == 1, 1,
                                                           ifelse(Fish.Final$Rock.Bass == 1, 1,
                                                                  ifelse(Fish.Final$Smallmouth.Bass == 1, 1,
                                                                         ifelse(Fish.Final$Sunfish == 1, 1,
                                                                                ifelse(Fish.Final$Sunnies == 1, 1, 0)))))))))

Fish.Final$Clupeidae      <- ifelse(Fish.Final$Gizzard.Shad == 1, 1, 0)

Fish.Final$Cyprinidae     <- ifelse(Fish.Final$Carp == 1, 1,
                               ifelse(Fish.Final$Chub == 1, 1,
                                      ifelse(Fish.Final$Dace == 1, 1,
                                             ifelse(Fish.Final$Golden.Shiner == 1, 1,
                                                    ifelse(Fish.Final$Minnow == 1, 1, 0)))))

Fish.Final$Esocidae       <- ifelse(Fish.Final$Muskies == 1, 1,
                               ifelse(Fish.Final$Northern.Pike == 1, 1,
                                      ifelse(Fish.Final$Pike == 1, 1, 0)))

Fish.Final$Gasterosteidae <- ifelse(Fish.Final$Stickleback == 1, 1, 0)

Fish.Final$Gobiidae       <- ifelse(Fish.Final$Round.Goby == 1, 1, 0)

Fish.Final$Ictaluridae    <- ifelse(Fish.Final$Bullhead == 1, 1,
                               ifelse(Fish.Final$Catfish == 1, 1,
                                      ifelse(Fish.Final$Channel.Catfish == 1, 1,
                                             ifelse(Fish.Final$Stonecat == 1, 1, 0))))

Fish.Final$Lepisosteidae  <- ifelse(Fish.Final$Gar == 1, 1, 0)

Fish.Final$Osmeridae      <- ifelse(Fish.Final$Rainbow.Smelt == 1, 1, 0)

Fish.Final$Percidae       <- ifelse(Fish.Final$Darter == 1, 1,
                               ifelse(Fish.Final$Perch == 1, 1,
                                      ifelse(Fish.Final$Sauger == 1, 1,
                                             ifelse(Fish.Final$Walleye == 1, 1,
                                                    ifelse(Fish.Final$Yellow.Perch == 1, 1, 0)))))

Fish.Final$Salmonidae     <- ifelse(Fish.Final$Brown.Trout == 1, 1,
                               ifelse(Fish.Final$Cisco == 1, 1,
                                      ifelse(Fish.Final$Trout == 1, 1,
                                             ifelse(Fish.Final$Whitefish == 1, 1, 0))))

Fish.Final$Sciaenidae     <- ifelse(Fish.Final$Drum == 1, 1,
                               ifelse(Fish.Final$Freshwater.Drum == 1, 1, 0))
# Export Fish.Final dataset
write.csv(Fish.Final, "data/raw/Fish_Final.csv", row.names = TRUE)
```

### Step 6: Preliminary map of fishkill observations

This is a preliminary map of fishkill events across Minnesota and Wisconsin to visually verify the waterbody centroid method.

```{r: Preliminary map}
# Subset data for a map
Fish.Map <- subset(Fish.Final, select = c(Lat, Long, Year, State))

# Remove events before 2003
Fish.Map$Year <- ifelse(Fish.Map$Year > 2000, Fish.Map$Year, NA)
Fish.Map      <- na.omit(Fish.Map)

# Create new event column
Fish.Map$Event <- c(1:646)

# Rename columns to match ggplot functions
names(Fish.Map)[1] <- "lat"
names(Fish.Map)[2] <- "long"
names(Fish.Map)[4] <- "region"

# Remove event that is appears to be outside the study region
Fish.Map$Event <- ifelse(Fish.Map$Event == 586, NA, Fish.Map$Event)
Fish.Map       <- na.omit(Fish.Map)

# Create state boundaries
states   <- map_data("state")
states   <- subset(states, region %in% c("minnesota", "wisconsin"))

# Create county boundaries
counties <- map_data("county")
counties <- subset(counties, region %in% c("minnesota", "wisconsin"))

# Preliminary map
ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + 
  coord_fixed(1.3) + 
  geom_polygon(data = counties, aes(x = long, y = lat, alpha = 0.1, group = group), color = "darkgray", fill = "gray", size = 0.5) +
  geom_polygon(data = states, color = "black", fill = NA, size = 1) +
  stat_density2d(data = Fish.Map, aes(x = long, y = lat, fill = ..level.., alpha = ..level.., group = region), bins = 30, geom = "polygon") +
  geom_point(data = Fish.Map, aes(x = long, y = lat, group = region),
             color = "black", fill = "darkolivegreen3", size = 2, shape = 21) +
  theme_nothing()

# Preliminary map with weather stations (run after going through air temperature step)
#ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + 
#  coord_fixed(1.3) + 
#  geom_polygon(data = counties, aes(x = long, y = lat, alpha = 0.1, group = group), color = "darkgray", fill = "gray", size = 0.5) +
#  geom_polygon(data = states, color = "black", fill = NA, size = 1) +
#  #stat_density2d(data = Fish.Map, aes(x = long, y = lat, fill = ..level.., alpha = ..level.., group = region), bins = 30, geom = "polygon") +
#  geom_point(data = Fish.Map, aes(x = long, y = lat, group = region),
#             color = "black", fill = "darkolivegreen3", size = 2, shape = 21) +
#  geom_point(data = temp.air.group2, aes(x = long_station, y = lat_station, group = NA), color = "red") +
#  theme_nothing()

# Remove unnecessary dataframes
rm(counties, states, Fish.Map)
```

### Step 7: Simplify fishkill dataset

This removes unused columns from the final fishkill dataset, then combines fishkill events that occurred in the same waterbody during the same month into a single fishkill event.

```{r: Simplify fishkill dataset}
# Reformat columns
Fish.Final$Investigation.Start.Date <- as.Date(Fish.Final$Investigation.Start.Date, "%d-%b-%y")
Fish.Final$WBIC <- as.character(Fish.Final$WBIC)
Fish.Final$Lat  <- as.character(Fish.Final$Lat)
Fish.Final$Long <- as.character(Fish.Final$Long)

# Reformat Fish.Final for use with Till et al. (2019) workflow
MME <- Fish.Final %>%
  rename_all(tolower) %>%
  mutate_all(tolower) %>%
  filter(investigation.start.date > "2003-01-01", investigation.start.date < "2014-05-01") %>%
  # dplyr::filter(min.kill.size!="excludable") %>% # Including all fishkill events for now since the MN estimates are low
  dplyr::select(site_id,
                lat,
                long,
                year,
                investigation.start.month,
                fishkill.inv.seq.no,
                cause.group) %>%
  rename(month = investigation.start.month) %>%
  mutate(dummy = 1,
         cause.categories = cause.group) %>% 
  spread(cause.categories, dummy, fill = 0) %>%
  #dplyr::select(-fishkill.inv.seq.no) %>%
  distinct(site_id, year, month, .keep_all = TRUE)

# Remove white space in thermal stress
colnames(MME)[c(11)] <- c("thermal_stress")

# Remove NAs
MME <- na.omit(MME)

# Export MME localities dataset
write.csv(MME, "data/raw/MME.csv", row.names = TRUE)

# Remove unnecessary dataframes
rm(Fish.Final)
```

### Step 8: Simplify water temperature dataset

These methods follow Till et al. (2019). In brieft, this removes water temperature data that predates the fishkill dataset, then processes the annual and monthly data separately for computational efficiency. For waterbodies with multiple site_ids, we average the annual and monthly data. For monthly data, the month is extracted from the variable name and turned into a datetime. Lastly, two features are added:

- `z-score`: calcuated for each water temperature variable via subtraction of the lake x monthly average then division by the SD.
- `water.temp`: single PC for water temperature data.

```{r: Simplify water temperature dataset}
# Reformat water temperature dataset
temp.water <- temp.water %>%
  rename_all(tolower) %>%
  filter(year >= 2003, year <= 2014) %>%
  mutate(year = as.character(year)) %>%
  dplyr::select(-contains("strat"),
                -sthermo_depth_mean)

# Reformat annual water temperature data
water.annual <- temp.water %>%
  dplyr::select(-contains('jas'),
                -starts_with('mean_surf_'),
                -starts_with('mean_bot_'), 
                -starts_with('max_surf_'), 
                -starts_with('max_bot_')) %>%
  group_by(site_id, year) %>% # Changed from WBIC in Till et al. (2019) workflow
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  ungroup() %>%
  rename(ice_duration = ice_duration_days,
         schmidt = schmidt_daily_annual_sum,
         variance_after_ice_30 = coef_var_0.30, 
         variance_after_ice_60 = coef_var_30.60, 
         cumulative_above_0 = gdd_wtr_0c,
         cumulative_above_5 = gdd_wtr_5c,
         cumulative_above_10 = gdd_wtr_10c) %>%
  mutate(log_schmidt = log(schmidt + .00001)) %>%
  dplyr::select(-prmnn_i, -gnis_id, -reachcd, -ftype, -fcode, -lat, -long)

# Reformat monthly water temperature data
water.month <- temp.water %>%
  dplyr::select(starts_with('mean_surf_'),
                starts_with('mean_bot_'), 
                starts_with('max_surf_'), 
                starts_with('max_bot_'),
                -contains('jas'),
                year, site_id) %>% # Changed from WBIC in Till et al. (2019) workflow
  mutate(uniqueid = 1:n()) %>%
  gather(key = "type", value = "temperature", 
         starts_with('mean_surf_'),
         starts_with('mean_bot_'), 
         starts_with('max_surf_'), 
         starts_with('max_bot_')) %>%
  separate(type, into=c('metric', 'depth', 'month'), sep='_')  %>%
  unite(metric, metric, depth) %>%
  spread(metric, temperature) %>%
 dplyr::select(-uniqueid) %>%
  group_by(site_id, year, month) %>% # Changed from WBIC in Till et al. (2019) workflow
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  ungroup() %>%
  arrange(site_id, year, month) %>% # Changed from WBIC in Till et al. (2019) workflow
  mutate(date = ymd(paste(year, month, "15"))) %>%
  filter(date > "2003-01-01", date < "2014-05-01")

# Scale monthly water temperature data and group by season
water.month <- water.month %>%
  group_by(site_id, month) %>% # Changed from WBIC in Till et al. (2019) workflow
  mutate(max_bot_z = scale(max_bot),
         max_surf_z = scale(max_surf),
         mean_bot_z = scale(mean_bot),
         mean_surf_z = scale(mean_surf)) %>%
  ungroup() %>%
  mutate(layer_diff = mean_surf - mean_bot,
         quadratic_temp = mean_surf^2,
         season = fct_collapse(month,
                               "winter" = "dec",
                               "winter" = "jan",
                               "winter" = "feb",
                               "spring" = "mar",
                               "spring" = "apr",
                               "spring" = "may",
                               "summer" = "jun",
                               "summer" = "jul",
                               "summer" = "aug",
                               "fall"   = "sep",
                               "fall"   = "oct",
                               "fall"   = "nov"))

# Perform PCA to collapse collinear covariates into a single variable (pca.water)
water.pr <- water.month %>%
  dplyr::select(max_surf, mean_surf, mean_bot) %>%
  prcomp(center = TRUE, scale = TRUE)

# Isolate PCA results into separate dataframe
water.pca <- water.month %>%
  dplyr::select(max_surf, mean_surf, mean_bot) %>%
  as.matrix() %*% water.pr$rotation[,1]

# Add PCA results into monthly water temperature data
water.month <- water.month %>%
  add_column(water.pca)

# Remove unnecessary dataframes
rm(water.pca, water.pr, temp.water)
```

### Step 9a: Simplify air temperature dataset (NOAA)

I manually downloaded daily air temperature data from NOAA for all Minnesota and Wisconsin weather stations ((https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND). Their online portal only allowed for downloads of ~6 months of data, so I  used Bash to concatenate all the daily temperature data files. To do this, I had to remove all headers and merge all the raw .csv files. Column names are then manually added to the joined dataset in R. The original air temperature files are located in "data/raw/temp_air", and the concatenated file (air_temp.csv) is located in data/raw/.

Note: There are many missing data from NOAA weather stations, so I am going to use PRISM from Oregon State (http://prism.oregonstate.edu) for historical air temperature estimates and CMIP5 for future temperrature projections (https://gdo-dcp.ucllnl.org/downscaled_cmip_projections/dcpInterface.html). More information on these datasets in Step 9b.

```{bash: Merge air temperature data (NOAA)}
#cd /Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp/data/raw/temp
#awk 'FNR>1' *.csv > ../air_temp.csv
```

I then reformatted the date columns across the datasets and calculate the monthly and annual averages of maximum, mean, and minimum air temperatures. Weather stations were then associated with the nearest waterbody centroid using their respective GPS coordinates. I did not scale and perform a pca for the monthly air temperature, as was done with the monthly water temperature, but there is code hashed out to do so if you think that is necessary.

```{r: Simplify air temperature dataset (NOAA)}
## Add headers for air temperature dataset
#names(temp.air) <- c("station_id", "station_name", "lat_station", "long_station",
#                     "elevation", "date", "mean_temp", "mean_attributes",
#                     "max_temp", "max_attributes", "min_temp", "min_attributes",
#                     "obs_temp", "obs_attributes")
#
## Remove unnecessary columns
#temp.air[,c("station_name", "elevation", "mean_attributes", "max_attributes",
#            "min_attributes", "obs_temp", "obs_attributes")] <- NULL
#
## Substitute / for - to condense dates
#temp.air$date <- gsub(pattern = "-", replacement = "/", x = temp.air$date)
#
## Split dates into year, month, and day columns
#temp.air[8:10] <- do.call('rbind', strsplit(as.character(temp.air$date), '/', fixed = TRUE))
#
## Add headers for air temperature dataset
#names(temp.air)[8:10] <- c("year", "month", "day")
#
## Reorganize date columns (NOAA used two different date formats; one for rows 1:35865, the other for rows 35966:2462091)
#month <- temp.air$year[1:35865]
#day   <- temp.air$month[1:35865]
#year  <- temp.air$day[1:35865]
#temp.air$year[1:35865]  <- paste0("20", year)
#temp.air$month[1:35865] <- month
#temp.air$day[1:35865]   <- day
#
## Remove unnecessary values
#rm(day, month, year)
#
## Subset data to timespan of interest
#temp.air$date <- paste(temp.air$year, temp.air$month, temp.air$day, sep = "-")
#temp.air$date <- as.Date(temp.air$date, format = "%Y-%m-%d")
#temp.air      <- subset(temp.air, date > "2003-01-01" & date < "2014-05-01")
#
#################################################################################
#
## Remove weather stations that lack data for comparison
##temp.air2 <- na.omit(temp.air)
#
## Group coordinates by station_id
#temp.air.group <- temp.air %>%
#  dplyr::select(station_id, lat_station, long_station) %>%
#  group_by(station_id) %>%
#  summarize(
#    lat_station  = mean(lat_station),
#    long_station = mean(long_station)) %>%
#  ungroup()
#
## Save station identification number (station_id) for later
#temp.station <- temp.air.group[1]
#
## Create spatial points for weather stations and waterbodies
#temp.station.sp  <- SpatialPoints(temp.air.group[, 2:3])
##temp.site.sp     <- SpatialPoints(Site.ID[, 9:10])
#MME$lat          <- as.numeric(MME$lat)
#MME$long         <- as.numeric(MME$long)
#temp.site.sp     <- SpatialPoints(MME[, 2:3])
#
## Find nearest lake centroid for each weather station
##temp.nearest <- apply(gDistance(temp.station.sp, temp.site.sp, byid = TRUE, hausdorff = TRUE), 2, which.min)
##temp.nearest <- gDistance(temp.station.sp, temp.site.sp, byid = TRUE, hausdorff = TRUE)
#temp.nearest <- apply(gDistance(temp.site.sp, temp.station.sp, byid = TRUE, hausdorff = TRUE), 2, which.min)
#
## Merge event number and nearest site_id data
#MME$Site <- as.vector(temp.nearest)
#
## Create Site column
#temp.station$Site <- 1:1250
#
## Merge fishkill event locations and estimated site_id locations
##temp.station <- merge(temp.nearest, Site.ID, by = "Site", all.x = TRUE, all.y = TRUE)
#temp.station <- merge(MME, temp.station, by = "Site", all.x = TRUE, all.y = TRUE)
#temp.station <- subset(temp.station, !is.na(temp.station$site_id))
#
## Reformat annual air temperature data
#air.annual <- temp.air %>%
#  mutate(station_id = as.character(station_id),
#         lat_station = as.numeric(lat_station),
#         long_station = as.numeric(long_station),
#         mean_temp = as.numeric(mean_temp),
#         max_temp = as.numeric(max_temp),
#         min_temp = as.numeric(min_temp),
#         year = as.character(year),
#         month = as.character(month),
#         day = as.character(day)) %>%
#  dplyr::select(mean_temp, max_temp, min_temp, station_id, year) %>%
#  group_by(station_id, year) %>%
#  summarize(
#    mean_temp = mean(mean_temp),
#    max_temp  = mean(max_temp),
#    min_temp  = mean(min_temp)) %>%
#  ungroup()
#  
## Reformat monthly air temperature data
#air.month <- temp.air %>%
#  mutate(station_id = as.character(station_id),
#         lat_station = as.numeric(lat_station),
#         long_station = as.numeric(long_station),
#         mean_temp = as.numeric(mean_temp),
#         max_temp = as.numeric(max_temp),
#         min_temp = as.numeric(min_temp),
#         year = as.character(year),
#         month = as.character(month),
#         day = as.character(day)) %>%
#  dplyr::select(mean_temp, max_temp, min_temp, station_id, month, year) %>%
#  group_by(station_id, year, month) %>%
#  summarize(
#    mean_temp = mean(mean_temp),
#    max_temp  = mean(max_temp),
#    min_temp  = mean(min_temp)) %>%
#  ungroup()
#
## Remove leading zero from months
#air.month$month <- gsub("(^|[^0-9])0+", "\\1", air.month$month, perl = TRUE)
#
## Relabel months
#air.month$month <- ifelse(air.month$month == "12", "dec",
#                           ifelse(air.month$month == "1", "jan",
#                                  ifelse(air.month$month == "2", "feb",
#                                         ifelse(air.month$month == "3", "mar",
#                                                ifelse(air.month$month == "4", "apr",
#                                                       ifelse(air.month$month == "5", "may",
#                                                              ifelse(air.month$month == "6", "jun",
#                                                                     ifelse(air.month$month == "7", "jul",
#                                                                            ifelse(air.month$month == "8", "aug",
#                                                                                   ifelse(air.month$month == "9", "sep",
#                                                                                          ifelse(air.month$month == "10", "oct",
#                                                                                                 ifelse(air.month$month == "11", "nov", "NA"))))))))))))
#
## Group months by season
#air.month <- air.month %>%
#  mutate(season = fct_collapse(month,
#                               "winter" = "dec",
#                               "winter" = "jan",
#                               "winter" = "feb",
#                               "spring" = "mar",
#                               "spring" = "apr",
#                               "spring" = "may",
#                               "summer" = "jun",
#                               "summer" = "jul",
#                               "summer" = "aug",
#                               "fall"   = "sep",
#                               "fall"   = "oct",
#                               "fall"   = "nov"))
#
## Create final monthly air temperature dataset
##air.month <- merge(temp.station, air.month, by = "station_id", all.x = TRUE, all.y = TRUE)
#air.month <- merge(temp.station, air.month, by = c("station_id", "month", "year"), all.x = TRUE, all.y = TRUE)
#air.month <- subset(air.month, !is.na(air.month$station_id))
#
## Create final annual air temperature dataset
##air.annual <- merge(temp.station, air.annual, by = "station_id", all.x = TRUE, all.y = TRUE)
#air.annual <- merge(temp.station, air.annual, by = c("station_id", "month", "year"), all.x = TRUE, all.y = TRUE)
#air.annual <- subset(air.annual, !is.na(air.annual$station_id))
#
## Remove unnecessary columns
#air.month[,c("Site", "Prmnn_I", "GNIS_ID", "GNIS_Nm", "ReachCd",
#                 "FType", "FCode")] <- NULL
#air.annual[,c("Site", "Prmnn_I", "GNIS_ID", "GNIS_Nm", "ReachCd",
#                 "FType", "FCode")] <- NULL
#
# Perform PCA to collapse collinear covariates into a single variable (pca.air)
#air.pr <- air.month %>%
#  dplyr::select(max_temp, mean_temp, min_temp) %>%
#  prcomp(center = TRUE, scale = TRUE)
#
## Isolate PCA results into separate dataframe
#air.pca <- air.month %>%
#  dplyr::select(max_temp, mean_temp, min_temp) %>%
#  as.matrix() %*% air.pr$rotation[,1]
#
## Add PCA results into monthly water temperature data
#air.month <- air.month %>%
#  add_column(air.pca)
#
## Remove unnecessary dataframes
#rm(temp.air, temp.air.group, temp.site.sp, temp.station, temp.station.sp, temp.nearest)
```

### Step 9b: Simplify air temperature dataset (PRISM)

Since there were many missing data from NOAA weather stations, I used historial air temperature estimates from PRISM Climate Group at Oregon State University (http://prism.oregonstate.edu). To do so, I exported the final fishkill dataset (MME) and submitted the latitude and longitude coordinates with a unique identifier (fishkill.inv.seq.no) for each event (MME_Localities_1/2.csv). All of these files are located in "data/raw/temp_air/PRISM".

For future air temperature, I downloaded the highest spatial resolution projections available (https://gdo-dcp.ucllnl.org/downscaled_cmip_projections/dcpInterface.html#Welcome) for all Coupled Model Intercomparison Project Phase 5 (CMIP5) models used in Winslow et al. (2017). These models are based on RCP 8.5, as were water temperature projections from Winslow et al. (2017), and include ACCESS, CNRM, GFDL, IPSL, MIROC5, and MRI. All of these files are located in "data/raw/temp_air/CMIP5".

```{r: Simplify air temperature dataset (CMIP5)}
# Split date
air.month[9:10] <- do.call('rbind', strsplit(as.character(air.month$Date), '-', fixed = TRUE))

# Remove old date column
air.month[,c("Date", "Longitude", "Latitude", "Elevation..ft.")] <- NULL

# Rename columns
colnames(air.month)[c(1:6)] <- c("fishkill.inv.seq.no", "temp_min", "temp_mean", "temp_max", "year", "month")


# Remove leading zero from months
air.month$month <- gsub("(^|[^0-9])0+", "\\1", air.month$month, perl = TRUE)

# Relabel months
air.month$month <- ifelse(air.month$month == "12", "dec",
                          ifelse(air.month$month == "1", "jan",
                                 ifelse(air.month$month == "2", "feb",
                                        ifelse(air.month$month == "3", "mar",
                                               ifelse(air.month$month == "4", "apr",
                                                      ifelse(air.month$month == "5", "may",
                                                             ifelse(air.month$month == "6", "jun",
                                                                    ifelse(air.month$month == "7", "jul",
                                                                           ifelse(air.month$month == "8", "aug",
                                                                                  ifelse(air.month$month == "9", "sep",
                                                                                         ifelse(air.month$month == "10", "oct",
                                                                                                ifelse(air.month$month == "11", "nov", "NA"))))))))))))

# Group months by season
air.month <- air.month %>%
  mutate(season = fct_collapse(month,
                               "winter" = "dec",
                               "winter" = "jan",
                               "winter" = "feb",
                               "spring" = "mar",
                               "spring" = "apr",
                               "spring" = "may",
                               "summer" = "jun",
                               "summer" = "jul",
                               "summer" = "aug",
                               "fall"   = "sep",
                               "fall"   = "oct",
                               "fall"   = "nov"))

# Reformat annual air temperature data
air.annual <- air.month %>%
  group_by(fishkill.inv.seq.no, year) %>%
  summarize(
    temp_min   = mean(temp_min),
    temp_mean  = mean(temp_mean),
    temp_max   = mean(temp_max)) %>%
  ungroup()

# Reformat columns
air.annual$fishkill.inv.seq.no <- as.character(air.annual$fishkill.inv.seq.no)
air.month$fishkill.inv.seq.no  <- as.character(air.month$fishkill.inv.seq.no)

```

### Step 10: Merge fishkill and thermal datasets

This merges the fishkill, water temperature, and air temperature datasets separately for monthly and annual data. Waterbodies that experienced a fishkill event but lack modeled water temperature data are removed.

```{r: Merge fishkill and thermal datasets}
# Save current global environment
save.image("test.RData")

# Load global environment
load("test.RData")

# Merge monthly air temperature data and MME dataframe
df.month <- air.month %>%
  left_join(MME, by = c("year", "month", "fishkill.inv.seq.no"))

# Fill in empty values for site_id, lat, and long
df.month <- df.month %>%
  fill(c(site_id, lat, long), .direction = c("down")) %>%
  dplyr::select(-season, -fishkill.inv.seq.no)

# Fill in empty values for MME causes
df.month$cause.group[is.na(df.month$cause.group)]       <- "none"
df.month$anthropogenic[is.na(df.month$anthropogenic)]   <- "0"
df.month$infectious[is.na(df.month$infectious)]         <- "0"
df.month$summerkill[is.na(df.month$summerkill)]         <- "0"
df.month$thermal_stress[is.na(df.month$thermal_stress)] <- "0"
df.month$unknown[is.na(df.month$unknown)]               <- "0"
df.month$winterkill[is.na(df.month$winterkill)]         <- "0"

# Merge monthly water temperature
df.month <- df.month %>%
  left_join(water.month, by = c("year", "month", "site_id")) %>%
  dplyr::select(-date, -lat, -long)

# Reorder columns
df.month <- df.month[, c(6, 4:5, 24, 1:3, 14:23, 25)]

# Rename columns for continuity
colnames(df.month)[c(5:7)] <- c("min_air", "mean_air", "max_air")

# Merge annual air temperature data and MME dataframe
df.annual <- air.annual %>%
  left_join(MME, by = c("year", "fishkill.inv.seq.no"))

# Fill in empty values for site_id, lat, and long
df.annual <- df.annual %>%
  fill(c(site_id, lat, long), .direction = c("down")) %>%
  dplyr::select(-month, -fishkill.inv.seq.no, -lat, -long)

# Fill in empty values for MME causes
df.annual$cause.group[is.na(df.annual$cause.group)]       <- "none"
df.annual$anthropogenic[is.na(df.annual$anthropogenic)]   <- "0"
df.annual$infectious[is.na(df.annual$infectious)]         <- "0"
df.annual$summerkill[is.na(df.annual$summerkill)]         <- "0"
df.annual$thermal_stress[is.na(df.annual$thermal_stress)] <- "0"
df.annual$unknown[is.na(df.annual$unknown)]               <- "0"
df.annual$winterkill[is.na(df.annual$winterkill)]         <- "0"

# Merge annual water temperature
df.annual <- df.annual %>%
  left_join(water.annual, by = c("year", "site_id"))

# Reorder columns
df.annual <- df.annual[, c(5, 1, 6:12, 2:4, 15:20, 22)]

# Rename columns for continuity
colnames(df.annual)[c(10:12)] <- c("min_air", "mean_air", "max_air")

# Remove unnecessary dataframes
rm(air.annual, air.month, water.annual, water.month, MME)
```

### Step 11: Add spatial data

This merges spatial covariates for each waterbody into the dataset, then adds 2010 population data from the US Census Bureau (https://www.census.gov/geo/maps-data/data/tiger-data.html) by matching waterbodies to the nearest GPS coordinates.

```{r: Add spatial data}
# Load spatial data
spatial <- readOGR(dsn=path.expand("data/raw/lake_shapes"), layer = "model_lakes")
spatial_df <- coordinates(spatial) %>%
  as.data.frame() %>%
  add_column(site_id = as.character(spatial@data$site_id)) %>%
  inner_join(Site.ID, by = "site_id") %>%
  rename(lat = V2,
         lon = V1) %>%
  dplyr::select(lat, lon, site_id)

# Represent each waterbody by a single GPS coordinate
spatial_df <- spatial_df %>%
  group_by(site_id) %>%
  summarize(lon = mean(lon),
            lat = mean(lat))

# Merge into annual dataset
df.annual <- df.annual %>%
  inner_join(spatial_df, by = "site_id")

# Merge into monthly dataset
df.month <- df.month %>%
  inner_join(spatial_df, by = "site_id")

# Add 2010 census data
census <- readOGR(dsn=path.expand("data/raw/census_data"), layer = "tabblock2010_55_pophu")
census_df <- coordinates(census) %>%
  as.data.frame() %>%
  add_column(population = census@data$POP10) %>%
  rename(lat = V2,
         lon = V1) %>%
  mutate(lon_round = round(lon, 1),
         lat_round = round(lat, 1)) %>%
  group_by(lon_round, lat_round) %>%
  summarize(population = sum(population)) %>%
  dplyr::select(lon_round, lat_round, population)

# Join population data with annual dataset by matching to the nearest GPS coordinates
df.annual <- df.annual %>%
  mutate(lon_round = round(lon, 1),
         lat_round = round(lat, 1)) %>%
  left_join(census_df, by = c("lon_round", "lat_round")) %>%
  dplyr::select(-lon_round, -lat_round)

# Join population data with monthly dataset by matching to the nearest GPS coordinates
df.month <- df.month %>%
  mutate(lon_round = round(lon, 1),
         lat_round = round(lat, 1)) %>%
  left_join(census_df, by = c("lon_round", "lat_round")) %>%
  dplyr::select(-lon_round, -lat_round)

# Remove unnecessary dataframe
rm(Site.ID, spatial, spatial_df, census, census_df)

# Save processed annual and monthly data
write_csv(df.annual, "data/processed/model_data_annual.csv")
write_csv(df.month,  "data/processed/model_data_month.csv")
```

### Step 12: Run 02_prepare_models.Rmd

######################################
######################################
######################################