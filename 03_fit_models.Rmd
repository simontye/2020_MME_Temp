---
title: "fit models"
author: "fishkill friends"
date: "2021/02/23"
output: github_document
---

### Background

Models are fit to the training data from `02_prepare_models` via four primary model families listed below. This is the same workflow as Till et al. (2019) except that I switched the file conversion from tibble to dataframe because of parsing errors (on my end).

1. Logistic regression
2. Ridge regression
3. Lasso regression
4. Logistic regression with random effects

### Step 1: Load packages and data

```{r: Load packages and data}
# Load packages
library(tidyverse)
library(rsample)
library(caret)
library(glmnet)
library(Matrix)
library(e1071)
library(pROC)
library(PRROC) 
library(glmnetUtils)
library(doParallel)
library(lme4)
library(optimx)


install.packages("FEM")
# Reset global environment
rm(list = ls())

# Set working directory
setwd("/Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp/data/models")

# Load data
training      <- read.csv(file = "training.csv", head = TRUE, sep = ",")
testing       <- read.csv(file = "testing.csv",  head = TRUE, sep = ",")
df.historical <- read.csv(file = "df_historical.csv", head = TRUE, sep = ",")

# Reformat training data
training <- training %>%
  mutate(year         = as.character(year),
         month        = as.character(month),
         season       = as.factor(season),
         summerkill   = as.factor(summerkill),
         lat          = as.numeric(lat),
         long         = as.numeric(long),
         population   = as.numeric(population),
         state        = as.factor(state),
         mean_surf_z  = as.numeric(mean_surf_z),
         water_pca    = as.numeric(water_pca),
         mean_air_z   = as.numeric(mean_air_z),
         air_pca      = as.numeric(air_pca))

# Reformat testing data
testing <- testing %>%
  mutate(year         = as.character(year),
         month        = as.character(month),
         season       = as.factor(season),
         summerkill   = as.factor(summerkill),
         lat          = as.numeric(lat),
         long         = as.numeric(long),
         population   = as.numeric(population),
         state        = as.factor(state),
         mean_surf_z  = as.numeric(mean_surf_z),
         water_pca    = as.numeric(water_pca),
         mean_air_z   = as.numeric(mean_air_z),
         air_pca      = as.numeric(air_pca))
```

### Step 2: Specify variable sets

Simple air and water models

```{r: Simple models}
# Air temperature model (all taxa)
a1 <- summerkill ~ long + lat + season + population +
  mean_air_z + air_pca + state

# Water temperature model (all taxa)
w1 <- summerkill ~ lat + long + season + population +
  mean_surf_z + water_pca + state
```

### Step 3: Set up lambda selection parameters for ridge and lasso regressions

Magic.

```{r: Set up parameters for ridge and lasso models}
# No downsampling
control_logloss <- trainControl(method = "repeatedcv",
                                number = 5,
                                repeats = 5,
                                summaryFunction = mnLogLoss,
                                classProbs = TRUE)

# Downsampling
control_logloss_ds <- trainControl(method = "repeatedcv",
                                   number = 5,
                                   repeats = 5,
                                   summaryFunction = mnLogLoss,
                                   classProbs = TRUE,
                                   sampling = "down")
```

### Step 4: Logistic regressions

Logistic models generalized models and stepwise comparisons

```{r: Logistic regression}
# Set seed
set.seed(736)

# New generalized model for air temperature
logistic_a1 <- glm(a1, training, family = "binomial")

# Save coefficients
logistic_a1_coef <- logistic_a1$coefficients

# Stepwise model comparisons by AIC
logistic_a1_stepwise <- step(logistic_a1)

# Save coefficients
logistic_a1_stepwise_coef <- logistic_a1_stepwise$coefficients

# New generalized model for water temperatures
logistic_w1 <- glm(w1, training, family = "binomial")

# Save coefficients
logistic_w1_coef <- logistic_w1$coefficients

# Stepwise model comparisons by AIC
logistic_w1_stepwise <- step(logistic_w1)

# Save coefficients
logistic_w1_stepwise_coef <- logistic_w1_stepwise$coefficients

# Save models 
write_rds(logistic_a1, "assessment/logistic_a1.rds")
write_rds(logistic_w1, "assessment/logistic_w1.rds")
write_rds(logistic_a1_stepwise, "assessment/logistic_a1_stepwise.rds")
write_rds(logistic_w1_stepwise, "assessment/logistic_w1_stepwise.rds")

## Remove models
#rm(logistic_a1, logistic_a1_stepwise,
#   logistic_w1, logistic_w1_stepwise)
```

### Step 5: Lasso regressions

Lasso models without downsampling and with different lambdas, utilizing a 5-fold CV scheme and repeated five times, on the training data.

```{r: Air temperature w/o downsampling}
# Magic (for remote computing)
#cl <- makePSOCKcluster(6)
#registerDoParallel(cl)

# Create grid of parameters
par_grid <-  expand.grid(alpha = 1, lambda = seq(1.5e-6, 1e-5, length.out = 6))

# Set seed
set.seed(685)

# Train lasso model without downsampling for air temperature
lasso_a1_logloss_train <- train(a1,
                                data      = training, 
                                method    = "glmnet", 
                                metric    = "LogLoss",
                                tuneGrid  = par_grid,
                                trControl = control_logloss)

# Print results
lasso_a1_logloss_train
# The final values used for the model were alpha = 1 and lambda = 1.5e-06.

# Subset summerkill from training data
lasso_a1_logloss_resp <- lasso_a1_logloss_train$trainingData %>%
  subset(., select = (".outcome")) %>%
  mutate(.outcome = as.factor(.outcome)) %>%
  data.matrix(.)

# Subset variables from training data
lasso_a1_logloss_vars <- lasso_a1_logloss_train$trainingData %>%
  subset(., select = c("long", "lat", "season", "population", "mean_air_z", "air_pca", "state")) %>%
  mutate(season = as.factor(season),
         state  = as.factor(state)) %>%
  data.matrix(.)

# Run best fit lasso model
lasso_a1_logloss <- glmnet(x = lasso_a1_logloss_vars, y = lasso_a1_logloss_resp,
                           family = "binomial", alpha = 1, lambda = 1.5e-06)

# Plot coefficients of best model
#plot(lasso_a1_logloss)

# Compare coefficients of best fit model
coef(lasso_a1_logloss_train$finalModel, lasso_a1_logloss_train$bestTune$lambda)
coef(lasso_a1_logloss)

# Save coefficients of best fit model
lasso_a1_logloss_coef <- coef(lasso_a1_logloss)

# Compare with testing data
#pred <- predict(lasso_a1_logloss, s = 1.5e-06, newx = XXX)

# Remove objects
rm(lasso_a1_logloss_train,
   lasso_a1_logloss_resp,
   lasso_a1_logloss_vars)
```

```{r: Water temperature w/o downsampling}
# Train lasso model without downsampling for air temperature
lasso_w1_logloss_train <- train(w1,
                                data      = training, 
                                method    = "glmnet", 
                                metric    = "LogLoss",
                                tuneGrid  = par_grid,
                                trControl = control_logloss)

# Print results
lasso_w1_logloss_train
# The final values used for the model were alpha = 1 and lambda = 3.2e-06.

# Subset summerkill from training data
lasso_w1_logloss_resp <- lasso_w1_logloss_train$trainingData %>%
  subset(., select = (".outcome")) %>%
  mutate(.outcome = as.factor(.outcome)) %>%
  data.matrix(.)

# Subset variables from training data
lasso_w1_logloss_vars <- lasso_w1_logloss_train$trainingData %>%
  subset(., select = c("long", "lat", "season", "population", "mean_surf_z", "water_pca", "state")) %>%
  mutate(season = as.factor(season),
         state  = as.factor(state)) %>%
  data.matrix(.)

# Run best fit lasso model
lasso_w1_logloss <- glmnet(x = lasso_w1_logloss_vars, y = lasso_w1_logloss_resp,
                           family = "binomial", alpha = 1, lambda = 3.2e-06)

# Plot coefficients of best model
#plot(lasso_w1_logloss)

# Compare coefficients of best fit model
coef(lasso_w1_logloss_train$finalModel, lasso_w1_logloss_train$bestTune$lambda)
coef(lasso_w1_logloss)

# Save coefficients of best fit model
lasso_w1_logloss_coef <- coef(lasso_w1_logloss)

# Compare with testing data
#pred <- predict(lasso_w1, s = 1.5e-06, newx = XXX)

# Remove objects
rm(lasso_w1_logloss_train,
   lasso_w1_logloss_resp,
   lasso_w1_logloss_vars)
```

```{r: Air temperature w/ downsampling}
# Magic (for remote computing)
#cl <- makePSOCKcluster(6)
#registerDoParallel(cl)

# Create grid of parameters
par_grid <-  expand.grid(alpha = 1, lambda = seq(1.5e-6, 1e-5, length.out = 6))

# Set seed
set.seed(685)

# Train lasso model without downsampling for air temperature
lasso_a1_logloss_ds_train <- train(a1,
                                   data      = training, 
                                   method    = "glmnet", 
                                   metric    = "LogLoss",
                                   tuneGrid  = par_grid,
                                   trControl = control_logloss_ds)

# Print results
lasso_a1_logloss_ds_train
# The final values used for the model were alpha = 1 and lambda = 1.5e-06.

# Subset summerkill from training data
lasso_a1_logloss_ds_resp <- lasso_a1_logloss_ds_train$trainingData %>%
  subset(., select = (".outcome")) %>%
  mutate(.outcome = as.factor(.outcome)) %>%
  data.matrix(.)

# Subset variables from training data
lasso_a1_logloss_ds_vars <- lasso_a1_logloss_ds_train$trainingData %>%
  subset(., select = c("long", "lat", "season", "population", "mean_air_z", "air_pca", "state")) %>%
  mutate(season = as.factor(season),
         state  = as.factor(state)) %>%
  data.matrix(.)

# Run best fit lasso model
lasso_a1_logloss_ds <- glmnet(x = lasso_a1_logloss_ds_vars, y = lasso_a1_logloss_ds_resp,
                              family = "binomial", alpha = 1, lambda = 1.5e-06)

# Plot coefficients of best model
#plot(lasso_a1_logloss_ds)

# Compare coefficients of best fit model
coef(lasso_a1_logloss_ds_train$finalModel, lasso_a1_logloss_ds_train$bestTune$lambda)
coef(lasso_a1_logloss_ds)

# Save coefficients of best fit model
lasso_a1_logloss_ds_coef <- coef(lasso_a1_logloss_ds)

# Compare with testing data
#pred <- predict(lasso_a1_logloss_ds, s = 1.5e-06, newx = XXX)

# Remove objects
rm(lasso_a1_logloss_ds_train,
   lasso_a1_logloss_ds_resp,
   lasso_a1_logloss_ds_vars)
```

```{r: Water temperature w/ downsampling}
# Train lasso model without downsampling for air temperature
lasso_w1_logloss_ds_train <- train(w1,
                                   data      = training, 
                                   method    = "glmnet", 
                                   metric    = "LogLoss",
                                   tuneGrid  = par_grid,
                                   trControl = control_logloss_ds)

# Print results
lasso_w1_logloss_ds_train
# The final values used for the model were alpha = 1 and lambda = 3.2e-06.

# Subset summerkill from training data
lasso_w1_ds_resp <- lasso_w1_logloss_ds_train$trainingData %>%
  subset(., select = (".outcome")) %>%
  mutate(.outcome = as.factor(.outcome)) %>%
  data.matrix(.)

# Subset variables from training data
lasso_w1_ds_vars <- lasso_w1_logloss_ds_train$trainingData %>%
  subset(., select = c("long", "lat", "season", "population", "mean_surf_z", "water_pca", "state")) %>%
  mutate(season = as.factor(season),
         state  = as.factor(state)) %>%
  data.matrix(.)

# Run best fit lasso model
lasso_w1_logloss_ds <- glmnet(x = lasso_w1_ds_vars, y = lasso_w1_ds_resp,
                              family = "binomial", alpha = 1, lambda = 3.2e-06)

# Plot coefficients of best model
#plot(lasso_w1)

# Compare coefficients of best fit model
coef(lasso_w1_logloss_ds_train$finalModel, lasso_w1_logloss_ds_train$bestTune$lambda)
coef(lasso_w1_logloss_ds)

# Save coefficients of best fit model
lasso_w1_logloss_ds_coef <- coef(lasso_w1_logloss_ds)

# Compare with testing data
#pred <- predict(lasso_w1, s = 1.5e-06, newx = XXX)

# Remove objects
rm(lasso_w1_logloss_ds_train,
   lasso_w1_logloss_ds_resp,
   lasso_w1_logloss_ds_vars)
```

### Step 6: Ridge logistic regressions

Ridge models with logloss and without downsampling.

```{r: Air temperature w/o downsampling}
# Create grid of parameters
par_grid <-  expand.grid(alpha = 0, lambda = seq(3.5e-7, 1.5e-5, length.out = 6))

## Magic (for remote computing)
#cl <- makePSOCKcluster(6)
#registerDoParallel(cl)

# Set seed
set.seed(475)

# Train ridge model without downsampling
ridge_a1_logloss_train <- train(a1, 
                                data      = training, 
                                method    = "glmnet",
                                metric    = "logLoss",
                                tuneGrid  = par_grid,
                                trControl = control_logloss)

# Print results
ridge_a1_logloss_train
# The final values used for the model were alpha = 0 and lambda = 9.14e-06.

# Subset summerkill from training data
ridge_a1_logloss_resp <- ridge_a1_logloss_train$trainingData %>%
  subset(., select = (".outcome")) %>%
  mutate(.outcome = as.factor(.outcome)) %>%
  data.matrix(.)

# Subset variables from training data
ridge_a1_logloss_vars <- ridge_a1_logloss_train$trainingData %>%
  subset(., select = c("long", "lat", "season", "population", "mean_air_z", "air_pca", "state")) %>%
  mutate(season = as.factor(season),
         state  = as.factor(state)) %>%
  data.matrix(.)

# Run best fit lasso model
ridge_a1_logloss <- glmnet(x = ridge_a1_logloss_vars, y = ridge_a1_logloss_resp,
                           family = "binomial", alpha = 0, lambda = 9.14e-06)

# Plot coefficients of best model
#plot(ridge_a1_logloss)

# Compare coefficients of best fit model
coef(ridge_a1_logloss_train$finalModel, ridge_a1_logloss_train$bestTune$lambda)
coef(ridge_a1_logloss)

# Save coefficients of best fit model
ridge_a1_logloss_coef <- coef(ridge_a1_logloss)

# Compare with testing data
#pred <- predict(ridge_a1_logloss, s = 3.2e-06, newx = XXX)

# Remove objects
rm(ridge_a1_logloss_train,
   ridge_a1_logloss_resp,
   ridge_a1_logloss_vars)
```

```{r: Water temperature w/o downsampling}
# Train ridge model without downsampling
ridge_w1_logloss_train <- train(w1, 
                                data      = training, 
                                method    = "glmnet",
                                metric    = "logLoss",
                                tuneGrid  = par_grid,
                                trControl = control_logloss)

# Print results
ridge_w1_logloss_train
# The final values used for the model were alpha = 0 and lambda = 9.14e-06.

# Subset summerkill from training data
ridge_w1_logloss_resp <- ridge_w1_logloss_train$trainingData %>%
  subset(., select = (".outcome")) %>%
  mutate(.outcome = as.factor(.outcome)) %>%
  data.matrix(.)

# Subset variables from training data
ridge_w1_logloss_vars <- ridge_w1_logloss_train$trainingData %>%
  subset(., select = c("long", "lat", "season", "population", "mean_surf_z", "water_pca", "state")) %>%
  mutate(season = as.factor(season),
         state  = as.factor(state)) %>%
  data.matrix(.)

# Run best fit lasso model
ridge_w1_logloss <- glmnet(x = ridge_w1_logloss_vars, y = ridge_w1_logloss_resp,
                           family = "binomial", alpha = 0, lambda = 9.14e-06)

# Plot coefficients of best model
#plot(ridge_w1_logloss)

# Compare coefficients of best fit model
coef(ridge_w1_logloss_train$finalModel, ridge_w1_logloss_train$bestTune$lambda)
coef(ridge_w1_logloss)

# Save coefficients of best fit model
ridge_w1_logloss_coef <- coef(ridge_w1_logloss)

# Compare with testing data
#pred <- predict(ridge_w1_logloss, s = 3.2e-06, newx = XXX)

# Remove objects
rm(ridge_w1_logloss_train,
   ridge_w1_logloss_resp,
   ridge_w1_logloss_vars)
```

```{r: Air temperature w/ downsampling}
# Train ridge model with downsampling
ridge_a1_logloss_ds_train <- train(a1, 
                                   data      = training, 
                                   method    = "glmnet",
                                   metric    = "logLoss",
                                   tuneGrid  = par_grid,
                                   trControl = control_logloss_ds)

# Print results
ridge_a1_logloss_ds_train
# The final values used for the model were alpha = 0 and lambda = 9.14e-06.

# Subset summerkill from training data
ridge_a1_logloss_ds_resp <- ridge_a1_logloss_ds_train$trainingData %>%
  subset(., select = (".outcome")) %>%
  mutate(.outcome = as.factor(.outcome)) %>%
  data.matrix(.)

# Subset variables from training data
ridge_a1_logloss_ds_vars <- ridge_a1_logloss_ds_train$trainingData %>%
  subset(., select = c("long", "lat", "season", "population", "mean_air_z", "air_pca", "state")) %>%
  mutate(season = as.factor(season),
         state  = as.factor(state)) %>%
  data.matrix(.)

# Run best fit lasso model
ridge_a1_logloss_ds <- glmnet(x = ridge_a1_logloss_ds_vars, y = ridge_a1_logloss_ds_resp,
                              family = "binomial", alpha = 0, lambda = 3.2e-06)

# Plot coefficients of best model
plot(ridge_a1_logloss_ds)

# Compare coefficients of best fit model
coef(ridge_a1_logloss_ds_train$finalModel, ridge_a1_logloss_ds_train$bestTune$lambda)
coef(ridge_a1_logloss_ds)

# Save coefficients of best fit model
ridge_a1_logloss_ds_coef <- coef(ridge_a1_logloss_ds_train)

# Compare with testing data
#pred <- predict(ridge_a1_logloss, s = 3.2e-06, newx = XXX)

# Remove objects
rm(lasso_a1_logloss_ds_train,
   lasso_a1_logloss_ds_resp,
   lasso_a1_logloss_ds_vars)
```

```{r: Water temperature w/ downsampling}
# Train ridge model with downsampling
ridge_w1_logloss_ds_train <- train(w1, 
                                   data      = training, 
                                   method    = "glmnet",
                                   metric    = "logLoss",
                                   tuneGrid  = par_grid,
                                   trControl = control_logloss_ds)

# Print results
ridge_w1_logloss_ds_train
# The final values used for the model were alpha = 0 and lambda = 9.14e-06.

# Subset summerkill from training data
ridge_w1_logloss_ds_resp <- ridge_w1_logloss_ds_train$trainingData %>%
  subset(., select = (".outcome")) %>%
  mutate(.outcome = as.factor(.outcome)) %>%
  data.matrix(.)

# Subset variables from training data
ridge_w1_logloss_ds_vars <- ridge_w1_logloss_ds_train$trainingData %>%
  subset(., select = c("long", "lat", "season", "population", "mean_air_z", "air_pca", "state")) %>%
  mutate(season = as.factor(season),
         state  = as.factor(state)) %>%
  data.matrix(.)

# Run best fit lasso model
ridge_w1_logloss_ds <- glmnet(x = ridge_w1_logloss_ds_vars, y = ridge_w1_logloss_ds_resp,
                              family = "binomial", alpha = 0, lambda = 3.2e-06)

# Plot coefficients of best model
plot(ridge_w1_logloss_ds)

# Compare coefficients of best fit model
coef(ridge_w1_logloss_ds_train$finalModel, ridge_w1_logloss_ds_train$bestTune$lambda)
coef(ridge_w1_logloss_ds)

# Save coefficients of best fit model
ridge_w1_logloss_ds_coef <- coef(ridge_w1_logloss_ds_train)

# Compare with testing data
#pred <- predict(ridge_w1_logloss, s = 3.2e-06, newx = XXX)

# Remove objects
rm(lasso_w1_logloss_ds_train,
   lasso_w1_logloss_ds_resp,
   lasso_w1_logloss_ds_vars)
```

### Step 7: Logistic regressions with random effects

```{r: First random effects logistic}
## Random effects model for water temperature
#w1_re <- summerkill ~ long + lat + season + variance_after_ice_30 + variance_after_ice_60 + log_schmidt +
#  cumulative_above_10 + ice_duration + water_pca + (1 | site_id)
#
## Magic
#re_w1 <- glmer(w1_re,
#               data = training, 
#               family = binomial, 
#               control = glmerControl(optimizer = "bobyqa"),
#               nAGQ = 10)
#
#### Warning messages:
#### 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
####   unable to evaluate scaled gradient
#### 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
####    Hessian is numerically singular: parameters are not uniquely determined
#   
## Magic (changed from lmer to glmer; removed unused argument (REML = FALSE))
#rf_w1 <- glmer(w1_re, 
#               data = training,
#               family = binomial,
#               control = glmerControl(optimizer = 'optimx',
#                                      optCtrl = list(method = 'L-BFGS-B')))
#
## Random effects model for air temperature
#a1_re <- summerkill ~ long + lat + season + air_pca + (1 | site_id)
#   
## Magic
#re_a1 <- glmer(a1_re,
#               data = training, 
#               family = binomial, 
#               control = glmerControl(optimizer = "bobyqa"),
#               nAGQ = 10)
#
#
## Magic (changed from lmer to glmer; removed unused argument (REML = FALSE))
#rf_a1 <- glmer(a1_re, 
#               data = training,
#               family = binomial,
#               control = glmerControl(optimizer = 'optimx',
#                                      optCtrl = list(method = 'L-BFGS-B')))
#
## Save models
#write_rds(re_w1, "assessment/re_w1.rds")
#write_rds(rf_w1, "assessment/rf_w1.rds")
#write_rds(re_a1, "assessment/re_a1.rds")
#write_rds(rf_a1, "assessment/rf_a1.rds")
#
## Remove models
#rm(re_w1, rf_w1,
#   re_a1, rf_a1)
```

######################################
Proceed to `04_assess_models.Rmd`
######################################
