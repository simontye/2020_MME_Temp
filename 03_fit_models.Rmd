---
title: "fit models"
author: "SPT"
date: "2022_05_06"
output: github_document
---

### Background

Models are fit to the training data from `02_prepare_models` via three model families:
1. Logistic regression
2. Ridge regression
3. Lasso regression

### Step 1: Load packages and data

```{r, setup, include = `FALSE`, echo = `FALSE`}
knitr::opts_knit$set(root.dir = "/Users/simontye/Research/Projects/MME_Temp/2020_MME_Temp/data/models")
```

```{r, echo = `FALSE`}
# Load packages
library(tidyverse)
library(rsample)
library(caret)
library(glmnet)
library(Matrix)
library(e1071)
library(pROC)
library(PRROC) 
library(glmnetUtils)
library(doParallel)
library(lme4)
library(optimx)
library(MLmetrics)

# Reset global environment
rm(list = ls())

# Set working directory
setwd("/Users/simontye/Research/Projects/MME_Temp/2020_MME_Temp/data/models")

# Load data
training    <- fread("training.csv")
testing     <- fread("testing.csv")
```

### Step 2: Verify formatting

```{r, echo = `FALSE`}
######################################
# Air variables
var.air.raw     <- c("max_air", "mean_air", "min_air")
var.air.z       <- c("max_air_z", "mean_air_z", "min_air_z")
var.air.pc      <- c("air_pc1", "air_pc2")
var.air.other   <- c("air_quad_temp", "precip", "ice_duration")
var.air         <- c(var.air.raw,
                     var.air.z,
                     var.air.pc,
                     var.air.other)

# Water variables
var.water.raw   <- c("max_bot", "max_surf", "mean_bot", "mean_surf")
var.water.z     <- c("max_surf_z", "mean_surf_z", "max_bot_z", "mean_bot_z")
var.water.other <- c("peak_temp", "layer_diff", "water_quad_temp",
                     "variance_after_ice_30", "variance_after_ice_60", "schmidt",
                     "cumulative_above_0", "cumulative_above_5", "cumulative_above_10")

var.water.pc    <- c("water_pc1", "water_pc2", "water_pc3")
var.water.s     <- c("max_surf", "mean_surf", "max_surf_z", "mean_surf_z")
var.water.b     <- c("max_bot", "mean_bot", "max_bot_z", "mean_bot_z")
var.water       <- c(var.water.raw,
                     var.water.z,
                     var.water.pc,
                     var.water.other)

# Productivity and lake size variables
var.lake        <- c("secchi_m", "size_km2")

# All variables
var.env.all     <- c(var.air, var.water, var.lake)

# Fish variables
var.fish   <- c("centrarchidae", "percidae", "esocidae", "ictaluridae",
                "cyprinidae", "salmonidae", "catostomidae", "sciaenidae",
                "clupeidae", "osmeridae", "lepisosteidae", "acipenseridae",
                "amiidae", "cottoidae", "gasterosteidae", "gobiidae",
                "fish_families", "fish_species")

# Cause variables
var.cause <- c("anthropogenic", "infectious", "summerkill", "winterkill", "unknown")          

# Fish thermal variables
var.temp  <- c("cold_temp", "cool_temp", "warm_temp", "unknown_temp")

# All fish variables
var.all.fish <-c(var.fish, var.temp, var.cause)

######################################
# Reduce training df for models
training <- training %>%
   mutate(
      year         = as.character(year),
      month        = as.character(month),
      season       = as.factor(season),
      summerkill   = as.factor(summerkill),
      lat          = as.numeric(lat),
      long         = as.numeric(long),
      state        = as.factor(state),
      population   = as.numeric(population),
      ice_duration = as.numeric(ice_duration)) %>%
   dplyr::select(., c(year, month, season, summerkill,
                     lat, long, state, population,
                     all_of(var.env.all)))

# Reduce testing df for models
testing <- testing %>%
    mutate(
      year         = as.character(year),
      month        = as.character(month),
      season       = as.factor(season),
      summerkill   = as.factor(summerkill),
      lat          = as.numeric(lat),
      long         = as.numeric(long),
      state        = as.factor(state),
      population   = as.numeric(population),
      ice_duration = as.numeric(ice_duration)) %>%
   dplyr::select(., c(year, month, season, summerkill,
                     lat, long, state, population,
                     all_of(var.env.all)))
```

### Step 3: Specify models

Set up simple and complex air and water temperature models for all taxa

```{r echo = `FALSE`}
######################################
### Air models

# Simple air model
a1 <- summerkill ~ lat + long + season + population +
   max_air + max_air_z + ice_duration + precip + secchi_m + size_km2

# Simple water model
w1 <- summerkill ~ lat + long + season + population +
   mean_surf + mean_surf_z + ice_duration + precip + secchi_m + size_km2

# Complex air model
a2 <- summerkill ~ lat + long + season + population +
  max_air + mean_air + min_air +
  max_air_z + mean_air_z + min_air_z +
  air_quad_temp + ice_duration + precip + secchi_m + size_km2

# Complex water model
w2 <- summerkill ~ lat + long + season + population +
  max_bot + mean_bot + max_surf + mean_surf +
  max_bot_z + mean_bot_z + max_surf_z + mean_surf_z +
  layer_diff + water_quad_temp + peak_temp + ice_duration + precip +
  cumulative_above_0 + secchi_m + size_km2

######################################

# No downsampling
control.logloss <- trainControl(method          = "repeatedcv",
                                number          = 5,
                                repeats         = 5,
                                summaryFunction = mnLogLoss,
                                classProbs      = TRUE)

# Downsampling
control.logloss.ds <- trainControl(method          = "repeatedcv",
                                   number          = 5,
                                   repeats         = 5,
                                   summaryFunction = mnLogLoss,
                                   classProbs      = TRUE,
                                   sampling        = "down")
```

### Step 4: Logistic regressions

Logistic models generalized models and stepwise comparisons

```{r echo = `FALSE`}
# Set seed
set.seed(736)

# Logistic regression model for air temperature
logistic_a1    <- glm(a1, training, family = "binomial")
logistic_a2    <- glm(a2, training, family = "binomial")
logistic_w1    <- glm(w1, training, family = "binomial")
logistic_w2    <- glm(w2, training, family = "binomial")

# Stepwise model comparisons by AIC
logistic_a1_stepwise    <- step(logistic_a1)
logistic_a2_stepwise    <- step(logistic_a2)
logistic_w1_stepwise    <- step(logistic_w1)
logistic_w2_stepwise    <- step(logistic_w2)

# Save models 
write_rds(logistic_a1,              "assessment/logistic_a1.rds")
write_rds(logistic_a1_stepwise,     "assessment/logistic_a1_stepwise.rds")
write_rds(logistic_a2,              "assessment/logistic_a2.rds")
write_rds(logistic_a2_stepwise,     "assessment/logistic_a2_stepwise.rds")
write_rds(logistic_w1,              "assessment/logistic_w1.rds")
write_rds(logistic_w1_stepwise,     "assessment/logistic_w1_stepwise.rds")
write_rds(logistic_w2,              "assessment/logistic_w2.rds")
write_rds(logistic_w2_stepwise,     "assessment/logistic_w2_stepwise.rds")

# Remove models
rm(logistic_a1, logistic_a1_stepwise,
   logistic_a2, logistic_a2_stepwise,
   logistic_w1, logistic_w1_stepwise,
   logistic_w2, logistic_w2_stepwise)
```

### Step 5: Lasso regressions

Lasso models with different lambdas. Uses 5-fold CV repeated five times on training data.

```{r echo = `FALSE`}
# Create grid of parameters
par_grid <- expand.grid(alpha = 1, lambda = seq(1.5e-6, 1e-5, length.out = 6))

# Set seed
set.seed(685)

# a1 model w/o downsampling
lasso_a1_train <- train(a1,
                        data      = training,
                        method    = "glmnet",
                        metric    = "logLoss",
                        tuneGrid  = par_grid,
                        trControl = control.logloss)

# a2 model w/o downsampling
lasso_a2_train <- train(a2,
                        data      = training,
                        method    = "glmnet",
                        metric    = "logLoss",
                        tuneGrid  = par_grid,
                        trControl = control.logloss)

# w1 model w/o downsampling
lasso_w1_train <- train(w1,
                        data      = training,
                        method    = "glmnet",
                        metric    = "logLoss",
                        tuneGrid  = par_grid,
                        trControl = control.logloss)

# w2 model w/o downsampling
lasso_w2_train <- train(w2,
                        data      = training,
                        method    = "glmnet",
                        metric    = "logLoss",
                        tuneGrid  = par_grid,
                        trControl = control.logloss)

## Run best fit lasso model
#lasso_a2_logloss <- glmnet(x = testing.a2, y = testing.resp,
#                           family = "binomial", alpha = 1,
#                           lambda = lasso_a2_logloss_train$bestTune$lambda)

## Calculate AIC
#deviance(lasso_a1_logloss) + 2 * dim(testing.air.vars)[2]
#deviance(lasso_a2_logloss) + 2 * dim(testing.air.vars)[2]

# Save models
write_rds(lasso_a1_train,     "assessment/lasso_a1.rds")
write_rds(lasso_a2_train,     "assessment/lasso_a2.rds")
write_rds(lasso_w1_train,     "assessment/lasso_w1.rds")
write_rds(lasso_w2_train,     "assessment/lasso_w2.rds")

# Remove objects
rm(lasso_a1_train, lasso_a2_train,
   lasso_w1_train, lasso_w2_train)
```

```{r echo = `FALSE`}
# Create grid of parameters
par_grid <- expand.grid(alpha = 1, lambda = seq(1.5e-6, 1e-5, length.out = 6))

# Set seed
set.seed(685)

# a1 model w/ downsampling
lasso_a1_ds_train <- train(a1,
                           data      = training,
                           method    = "glmnet",
                           metric    = "logLoss",
                           tuneGrid  = par_grid,
                           trControl = control.logloss.ds)

# a2 model w/ downsampling
lasso_a2_ds_train <- train(a2,
                           data      = training,
                           method    = "glmnet",
                           metric    = "logLoss",
                           tuneGrid  = par_grid,
                           trControl = control.logloss.ds)

# w1 model w/ downsampling
lasso_w1_ds_train <- train(w1,
                           data      = training,
                           method    = "glmnet",
                           metric    = "logLoss",
                           tuneGrid  = par_grid,
                           trControl = control.logloss.ds)

# w2 model w/ downsampling
lasso_w2_ds_train <- train(w2,
                           data      = training,
                           method    = "glmnet",
                           metric    = "logLoss",
                           tuneGrid  = par_grid,
                           trControl = control.logloss.ds)

# Save models
write_rds(lasso_a1_ds_train,     "assessment/lasso_a1_ds.rds")
write_rds(lasso_a2_ds_train,     "assessment/lasso_a2_ds.rds")
write_rds(lasso_w1_ds_train,     "assessment/lasso_w1_ds.rds")
write_rds(lasso_w2_ds_train,     "assessment/lasso_w2_ds.rds")

# Remove objects
rm(lasso_a1_ds_train, lasso_a2_ds_train,
   lasso_w1_ds_train, lasso_w2_ds_train)
```

### Step 6: Ridge logistic regressions

Ridge models with different lambdas.

```{r echo = `FALSE`}
# Create grid of parameters
par_grid <-  expand.grid(alpha = 0, lambda = seq(3.5e-7, 1.5e-5, length.out = 6))

# Set seed
set.seed(475)

# a1 model w/o downsampling
ridge_a1_train <- train(a1,
                        data      = training,
                        method    = "glmnet",
                        metric    = "logLoss",
                        tuneGrid  = par_grid,
                        trControl = control.logloss)

# a2 model w/o downsampling
ridge_a2_train <- train(a2,
                        data      = training,
                        method    = "glmnet",
                        metric    = "logLoss",
                        tuneGrid  = par_grid,
                        trControl = control.logloss)

# w1 model w/o downsampling
ridge_w1_train <- train(w1,
                        data      = training,
                        method    = "glmnet",
                        metric    = "logLoss",
                        tuneGrid  = par_grid,
                        trControl = control.logloss)

# w2 model w/o downsampling
ridge_w2_train <- train(w2,
                        data      = training,
                        method    = "glmnet",
                        metric    = "logLoss",
                        tuneGrid  = par_grid,
                        trControl = control.logloss)

## Run best fit ridge model
#ridge_a2_logloss <- glmnet(x = testing.a2, y = testing.resp,
#                           family = "binomial", alpha = 1,
#                           lambda = ridge_a2_logloss_train$bestTune$lambda)

## Calculate AIC
#deviance(ridge_a1_logloss) + 2 * dim(testing.air.vars)[2]
#deviance(ridge_a2_logloss) + 2 * dim(testing.air.vars)[2]

# Save models
write_rds(ridge_a1_train,        "assessment/ridge_a1.rds")
write_rds(ridge_a2_train,        "assessment/ridge_a2.rds")
write_rds(ridge_w1_train,        "assessment/ridge_w1.rds")
write_rds(ridge_w2_train,        "assessment/ridge_w2.rds")

# Remove objects
rm(ridge_a1_train, ridge_a2_train,
   ridge_w1_train, ridge_w2_train)
```

```{r echo = `FALSE`}
# Create grid of parameters
par_grid <-  expand.grid(alpha = 0, lambda = seq(3.5e-7, 1.5e-5, length.out = 6))

# Set seed
set.seed(475)

# a1 model w/ downsampling
ridge_a1_ds_train <- train(a1,
                           data      = training,
                           method    = "glmnet",
                           metric    = "logLoss",
                           tuneGrid  = par_grid,
                           trControl = control.logloss.ds)

# a2 model w/ downsampling
ridge_a2_ds_train <- train(a2,
                           data      = training,
                           method    = "glmnet",
                           metric    = "logLoss",
                           tuneGrid  = par_grid,
                           trControl = control.logloss.ds)

# w1 model w/ downsampling
ridge_w1_ds_train <- train(w1,
                           data      = training,
                           method    = "glmnet",
                           metric    = "logLoss",
                           tuneGrid  = par_grid,
                           trControl = control.logloss.ds)

# w2 model w/ downsampling
ridge_w2_ds_train <- train(w2,
                           data      = training,
                           method    = "glmnet",
                           metric    = "logLoss",
                           tuneGrid  = par_grid,
                           trControl = control.logloss.ds)

## Run best fit ridge model
#ridge_a2_logloss <- glmnet(x = testing.a2, y = testing.resp,
#                           family = "binomial", alpha = 1,
#                           lambda = ridge_a2_logloss_train$bestTune$lambda)

## Calculate AIC
#deviance(ridge_a1_logloss) + 2 * dim(testing.air.vars)[2]
#deviance(ridge_a2_logloss) + 2 * dim(testing.air.vars)[2]

# Save models
write_rds(ridge_a1_ds_train,    "assessment/ridge_a1_ds.rds")
write_rds(ridge_a2_ds_train,    "assessment/ridge_a2_ds.rds")
write_rds(ridge_w1_ds_train,    "assessment/ridge_w1_ds.rds")
write_rds(ridge_w2_ds_train,    "assessment/ridge_w2_ds.rds")

# Remove objects
rm(ridge_a1_ds_train, ridge_a2_ds_train,
   ridge_w1_ds_train, ridge_w2_ds_train)
```

######################################
Proceed to `04_assess_models.Rmd`
######################################
