---
title: "fit models"
author: "fishkill friends"
date: "2020/11/10"
output: github_document
---

### Background

Models are fit to the training data from `02_prepare_models` via four primary model families listed below. This is the same workflow as Till et al. (2019) except that I switched the file conversion from tibble to dataframe because of parsing errors.

1. Logistic regression
2. Ridge regression
3. Lasso regression
4. Logistic regression with random effects

### Step 1: Load packages and data

```{r: Load packages and data}
# Load packages
library(tidyverse)
library(rsample)
library(caret)
library(glmnet)
library(Matrix)
library(e1071)
library(pROC)
library(PRROC) 
library(glmnetUtils)
library(doParallel)
library(lme4)
library(optimx)

# Reset global environment
rm(list = ls())

# Set working directory
setwd("/Users/simontye/Documents/Research/Projects/MME_Temp/2020_MME_Temp/data/models")

# Load data
training <- read.csv(file = "training.csv", head = TRUE, sep = ",")
testing  <- read.csv(file = "testing.csv",  head = TRUE, sep = ",")

# Reformat training data
training <- training %>%
  mutate(site_id      = as.character(site_id),
         year         = as.character(year),
         month        = as.character(month),
         season       = as.character(season),
         summerkill   = as.factor(summerkill),
         ice_duration = as.double(ice_duration),
         pop_2010     = as.numeric(pop_2010))

# Reformat testing data
testing <- testing %>%
  mutate(site_id      = as.character(site_id),
         year         = as.character(year),
         month        = as.character(month),
         season       = as.character(season),
         summerkill   = as.factor(summerkill),
         ice_duration = as.double(ice_duration),
         pop_2010     = as.numeric(pop_2010))
```

### Step 2: Specify variable sets

The first generalized model uses a subset of variables selected based on their presumed effect and not being mutually non-correlated (at least strongly). Throughout the remaining code, models that are based on air or water temperature begin with "a" or "w", respectively.

```{r: First generalized model}
# Simple generalized model for water temperature (ecoregion)
w1e <- summerkill ~ long + lat + season + pop_2010 +
  variance_after_ice_30 + variance_after_ice_60 +
  log_schmidt + cumulative_above_10 + ice_duration +
  water_pca + l3_code

# Simple generalized model for air temperature (ecoregion)
a1e <- summerkill ~ long + lat + season + pop_2010 +
  air_pca + l3_code

# Simple generalized model for water temperature (state)
w1s <- summerkill ~ long + lat + season + pop_2010 +
  variance_after_ice_30 + variance_after_ice_60 +
  log_schmidt + cumulative_above_10 + ice_duration +
  water_pca + state

# Simple generalized model for air temperature (state)
a1s <- summerkill ~ long + lat + season + pop_2010 +
  air_pca + state

# Simple generalized model for water temperature (state and ecoregion)
w1se <- summerkill ~ long + lat + season + pop_2010 +
  variance_after_ice_30 + variance_after_ice_60 +
  log_schmidt + cumulative_above_10 + ice_duration +
  water_pca + state + l3_code

# Simple generalized model for air temperature (state and ecoregion)
a1se <- summerkill ~ long + lat + season + pop_2010 +
  air_pca + state + l3_code
```

The second model involves all covariates except site_id, which we treat separately because of the number of levels.

```{r: Second generalized model}
# Complex generalized model for water temperature (ecoregion)
w2e <- summerkill ~ long + lat + season + pop_2010 +
  variance_after_ice_30 + variance_after_ice_60 + log_schmidt +
  cumulative_above_10 + cumulative_above_5 + cumulative_above_0 +
  max_bot + max_surf + mean_bot + mean_surf +
  max_bot_z + max_surf_z + mean_bot_z + mean_surf_z +
  ice_duration + layer_diff + water_quad_temp + peak_temp +
  l3_code

# Complex generalized model for air temperature (ecoregion)
a2e <- summerkill ~ long + lat + season +
  min_air + mean_air + max_air + 
  min_air_z + mean_air_z + max_air_z +
  air_quad_temp + l3_code

# Complex generalized model for water temperature (state)
w2s <- summerkill ~ long + lat + season + pop_2010 +
  variance_after_ice_30 + variance_after_ice_60 + log_schmidt +
  cumulative_above_10 + cumulative_above_5 + cumulative_above_0 +
  max_bot + max_surf + mean_bot + mean_surf +
  max_bot_z + max_surf_z + mean_bot_z + mean_surf_z +
  ice_duration + layer_diff + water_quad_temp + peak_temp +
  state

# Complex generalized model for air temperature (state)
a2s <- summerkill ~ long + lat + season +
  min_air + mean_air + max_air + 
  min_air_z + mean_air_z + max_air_z +
  air_quad_temp + state

# Complex generalized model for water temperature (state and ecoregion)
w2se <- summerkill ~ long + lat + season + pop_2010 +
  variance_after_ice_30 + variance_after_ice_60 + log_schmidt +
  cumulative_above_10 + cumulative_above_5 + cumulative_above_0 +
  max_bot + max_surf + mean_bot + mean_surf +
  max_bot_z + max_surf_z + mean_bot_z + mean_surf_z +
  ice_duration + layer_diff + water_quad_temp + peak_temp +
  state + l3_code

# Complex generalized model for air temperature (state and ecoregion)
a2se <- summerkill ~ long + lat + season +
  min_air + mean_air + max_air + 
  min_air_z + mean_air_z + max_air_z +
  air_quad_temp + state + l3_code
```

### Step 3: Set up parameters for lambda selection for ridge and lasso regressions

Black magic.

```{r: Set up parameters for ridge and lasso models}
# No down sampling
control_logloss <- trainControl(method = "repeatedcv",
                                number = 5,
                                repeats = 5,
                                summaryFunction = mnLogLoss,
                                classProbs = TRUE)

# Down sampling
control_logloss_ds <- trainControl(method = "repeatedcv",
                                   number = 5,
                                   repeats = 5,
                                   summaryFunction = mnLogLoss,
                                   classProbs = TRUE,
                                   sampling = "down")
```

### Step 4: Logistic regressions

First set of generalized models (w1 and a1)

```{r: First logistic regression}
# Set seed
set.seed(432)

### Water

# First generalized model for water temperature
logistic_w1e <- glm(w1, training, family = "binomial")

# Stepwise model comparisons by AIC
logistic_w1e <- step(logistic_w1e)

# First generalized model for water temperature
logistic_w1s <- glm(w1, training, family = "binomial")

# Stepwise model comparisons by AIC
logistic_w1s <- step(logistic_w1s)

# First generalized model for air temperature
logistic_w1se <- glm(a1, training, family = "binomial")

# Stepwise model comparisons by AIC
logistic_w1se <- step(logistic_w1se)

### Air

# First generalized model for water temperature
logistic_a1e <- glm(w1, training, family = "binomial")

# Stepwise model comparisons by AIC
logistic_a1e <- step(logistic_a1e)

# First generalized model for water temperature
logistic_a1s <- glm(w1, training, family = "binomial")

# Stepwise model comparisons by AIC
logistic_a1s <- step(logistic_a1s)

# First generalized model for air temperature
logistic_a1se <- glm(a1, training, family = "binomial")

# Stepwise model comparisons by AIC
logistic_a1se <- step(logistic_a1se)

# Save models
write_rds(logistic_w1e,  "assessment/logistic_w1e.rds")
write_rds(logistic_w1s,  "assessment/logistic_w1s.rds")
write_rds(logistic_w1se, "assessment/logistic_w1se.rds")
write_rds(logistic_a1e,  "assessment/logistic_a1e.rds")
write_rds(logistic_a1s,  "assessment/logistic_a1s.rds")
write_rds(logistic_a1se, "assessment/logistic_a1se.rds")

# Remove models
rm(logistic_w1e.rds, logistic_w1s.rds,
   logistic_w1se.rds, logistic_a1e.rds,
   logistic_a1s.rds, logistic_a1se.rds)
```

Second set of generalized model (w2 and a2)

```{r: Second logistic regression}
# Second generalized model for water temperature
logistic_w2 <- glm(w2, training, family = "binomial") 

# glm.fit: fitted probabilities numerically 0 or 1 occurred 

# Stepwise model comparisons by AIC
logistic_w2 <- step(logistic_w2)

# Second generalized model for air temperature
logistic_a2 <- glm(a2, training, family = "binomial") 

# glm.fit: fitted probabilities numerically 0 or 1 occurred 

# Stepwise model comparisons by AIC
logistic_a2 <- step(logistic_a2)

# Save models
write_rds(logistic_w2, "assessment/logistic_w2.rds")
write_rds(logistic_a2, "assessment/logistic_a2.rds")

# Remove models
rm(logistic_w2, logistic_a2)
```

### Step 5: Lasso regressions

This fits LASSO models with many differenct lambdas, utilizing a 5-fold CV scheme, repeated five times, on the training data.

First set of models with logloss and without downsampling (w1 and a1). Note that this suffers from unidentifiability in lambda (from Till).

```{r: First lasso regression w/o downsampling}
# Black magic
cl <- makePSOCKcluster(6)
registerDoParallel(cl)

# Black magic
par_grid <-  expand.grid(alpha = 1, lambda = seq(1.5e-6, 1e-5, length.out = 6))

# Set seed
set.seed(685)

# First lasso model for water temperature
lasso_w1_logloss <- train(w1,
                     data = training, 
                     method = "glmnet", 
                     metric = "mnLogLoss",
                     tuneGrid = par_grid,
                     trControl = control_logloss)

### Warning messages:
### 1: In train.default(x, y, weights = w, ...) :
###   The metric "mnLogLoss" was not in the result set. logLoss will be used instead.
### 2: In .Internal(gc(verbose, reset, full)) :
###   closing unused connection 8 (<-localhost:11023)
### 3: In .Internal(gc(verbose, reset, full)) :
###   closing unused connection 7 (<-localhost:11023)
### 4: In .Internal(gc(verbose, reset, full)) :
###   closing unused connection 6 (<-localhost:11023)
### 5: In .Internal(gc(verbose, reset, full)) :
###   closing unused connection 5 (<-localhost:11023)
### 6: In .Internal(gc(verbose, reset, full)) :
###   closing unused connection 4 (<-localhost:11023)
### 7: In .Internal(gc(verbose, reset, full)) :
###   closing unused connection 3 (<-localhost:11023)

# First lasso model for air temperature
lasso_a1_logloss <- train(a1,
                     data = training, 
                     method = "glmnet", 
                     metric = "mnLogLoss",
                     tuneGrid = par_grid,
                     trControl = control_logloss)

### Warning message:
### In train.default(x, y, weights = w, ...) :
###   The metric "mnLogLoss" was not in the result set. logLoss will be used instead.

# Black magic
stopCluster(cl)

# Save models
write_rds(lasso_w1_logloss, "assessment/lasso_w1_logloss.rds")
write_rds(lasso_a1_logloss, "assessment/lasso_a1_logloss.rds")

# Remove models
rm(lasso_w1_logloss, lasso_a1_logloss)
```

First set of models with logloss and downsampling (w1 and a1).

```{r: First lasso regression w/ downsampling}
# Black magic
cl <- makePSOCKcluster(4)

# Black magic
registerDoParallel(cl)

# Black magic
par_grid <-  expand.grid(alpha = 1, lambda = 10^seq(-3.5, -1.3, length = 8))

# Set seed
set.seed(336)

# First lasso model for water temperature
lasso_w1_logloss_downsampled <- train(w1, 
                                      data = training, 
                                      method = "glmnet", 
                                      metric = "logLoss",
                                      tuneGrid = par_grid,
                                      trControl = control_logloss_ds)

# First lasso model for air temperature
lasso_a1_logloss_downsampled <- train(a1, 
                                      data = training, 
                                      method = "glmnet", 
                                      metric = "logLoss",
                                      tuneGrid = par_grid,
                                      trControl = control_logloss_ds)

# Black magic
stopCluster(cl)

# Save models
write_rds(lasso_w1_logloss_downsampled, "assessment/lasso_w1_logloss_downsampled.rds")
write_rds(lasso_a1_logloss_downsampled, "assessment/lasso_a1_logloss_downsampled.rds")

# Remove models
rm(lasso_w1_logloss_downsampled, lasso_a1_logloss_downsampled)
```

Second set of models with logloss and downsampling (w2 and a2). Note that this suffers from unidentifiability in lambda (from Till).

```{r: Second lasso regression w/o downsampling}
# Black magic
cl <- makePSOCKcluster(6)

# Black magic
registerDoParallel(cl)

# Black magic (was hashed out in Till)
#par_grid <-  expand.grid(alpha = 1, lambda = seq(1.5e-6, 1e-5, length.out = 6))

# Set seed
set.seed(192)

# Second lasso model for water temperature
lasso_w2_logloss <- train(w2, 
                     data = training, 
                     method = "glmnet", 
                     metric = "mnLogLoss",
                     #tuneGrid = par_grid,
                     trControl = control_logloss)

### Warning message:
### In train.default(x, y, weights = w, ...) :
###   The metric "mnLogLoss" was not in the result set. logLoss will be used instead.

# Second lasso model for air temperature
lasso_a2_logloss <- train(a2, 
                     data = training, 
                     method = "glmnet", 
                     metric = "mnLogLoss",
                     #tuneGrid = par_grid,
                     trControl = control_logloss)

### Warning message:
### In train.default(x, y, weights = w, ...) :
###   The metric "mnLogLoss" was not in the result set. logLoss will be used instead.

# Black magic
stopCluster(cl)

# Save models
write_rds(lasso_w2_logloss, "assessment/lasso_w2_logloss.rds")
write_rds(lasso_a2_logloss, "assessment/lasso_a2_logloss.rds")

# Remove models
rm(lasso_w2_logloss, lasso_a2_logloss)
```

Second set of models with logloss and downsampling (w2 and a2).

```{r: Second lasso regression w/ downsampling}
# Black magic
cl <- makePSOCKcluster(6)
registerDoParallel(cl)

# Black magic (was hashed out in Till)
#par_grid <-  expand.grid(alpha = 1,
                        # lambda = seq(1.5e-6, 1e-5, 
                        #              length.out = 6))

# Set seed
set.seed(697)

# Second lasso model for water temperature
lasso_w2_logloss_downsampled <- train(w2, 
                                      data = training, 
                                      method = "glmnet", 
                                      metric = "mnLogLoss",
                                      #tuneGrid = par_grid,
                                      trControl = control_logloss_ds)

### Warning message:
### In train.default(x, y, weights = w, ...) :
###   The metric "mnLogLoss" was not in the result set. logLoss will be used instead.

# Second lasso model for water temperature
lasso_a2_logloss_downsampled <- train(a2, 
                                      data = training, 
                                      method = "glmnet", 
                                      metric = "mnLogLoss",
                                      #tuneGrid = par_grid,
                                      trControl = control_logloss_ds)

### Warning message:
### In train.default(x, y, weights = w, ...) :
###   The metric "mnLogLoss" was not in the result set. logLoss will be used instead.

# Black magic
stopCluster(cl)

# Save models
write_rds(lasso_w2_logloss_downsampled, "assessment/lasso_w2_logloss_downsampled.rds")
write_rds(lasso_a2_logloss_downsampled, "assessment/lasso_a2_logloss_downsampled.rds")

# Remove models
rm(lasso_w2_logloss_downsampled, lasso_a2_logloss_downsampled)
```

### Step 6: Ridge logistic regressions

First set of models with logloss and without downsampling (w1 and a1). Note that this suffers from unidentifiability in lambda (from Till).

```{r: First ridge regression w/o downsampling}
# Black magic
par_grid <-  expand.grid(alpha = 0,
                        lambda = seq(3.5e-7, 1.5e-5,
                                     length.out = 6))

# Black magic
cl <- makePSOCKcluster(6)
registerDoParallel(cl)

# Set seed
set.seed(475)

# First ridge model for water temperature
ridge_w1_logloss <- train(w1, 
                          data = training, 
                          method = "glmnet",
                          metric = "logLoss",
                          tuneGrid = par_grid,
                          trControl = control_logloss)

# First ridge model for water temperature
ridge_a1_logloss <- train(a1, 
                          data = training, 
                          method = "glmnet",
                          metric = "logLoss",
                          tuneGrid = par_grid,
                          trControl = control_logloss)
# Black magic
stopCluster(cl)

# Save models
write_rds(ridge_w1_logloss, "assessment/ridge_w1_logloss.rds")
write_rds(ridge_a1_logloss, "assessment/ridge_a1_logloss.rds")

# Remove models
rm(ridge_w1_logloss, ridge_a1_logloss)
```

First set of models with logloss and downsampling (w1 and a1).

```{r: First ridge regression w/ downsampling}
# Black magic
par_grid <-  expand.grid(alpha = 0,
                        lambda = seq(3.5e-8, 3.5e7,
                                     length.out = 8))

# Black magic
cl <- makePSOCKcluster(6)
registerDoParallel(cl)

# Sed seed
set.seed(284)

# First ridge model for water temperature
ridge_w1_logloss_downsampled <- train(w1, 
                                      data = training, 
                                      method = "glmnet",
                                      metric = "logLoss",
                                      tuneGrid = par_grid,
                                      trControl = control_logloss_ds)

# First ridge model for air temperature
ridge_a1_logloss_downsampled <- train(a1, 
                                      data = training, 
                                      method = "glmnet",
                                      metric = "logLoss",
                                      tuneGrid = par_grid,
                                      trControl = control_logloss_ds)

# Black magic
stopCluster(cl)

# Save models
write_rds(ridge_w1_logloss_downsampled, "assessment/ridge_w1_logloss_downsampled.rds")
write_rds(ridge_a1_logloss_downsampled, "assessment/ridge_a1_logloss_downsampled.rds")

# Remove models
rm(ridge_w1_logloss_downsampled, ridge_a1_logloss_downsampled)
```

Second set of models with logloss and downsampling (w2 and a2).

```{r: Second ridge regression w/o downsampling}
# Black magic
par_grid <-  expand.grid(alpha = 0,
                        lambda = seq(.01, .25, 
                                     length.out = 8))

# Black magic
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

# Set seed
set.seed(952)

# Second ridge model for water temperature
ridge_w2_logloss_downsampled <- train(w2, 
                                      data = training, 
                                      method = "glmnet", 
                                      metric = "logLoss",
                                      tuneGrid = par_grid,
                                      trControl = control_logloss_ds)

# Second ridge model for air temperature
ridge_a2_logloss_downsampled <- train(a2, 
                                      data = training, 
                                      method = "glmnet", 
                                      metric = "logLoss",
                                      tuneGrid = par_grid,
                                      trControl = control_logloss_ds)
# Black magic
stopCluster(cl)

# Save models
write_rds(ridge_w2_logloss_downsampled, "assessment/ridge_w2_logloss_downsampled.rds")
write_rds(ridge_a2_logloss_downsampled, "assessment/ridge_a2_logloss_downsampled.rds")

# Remove models
rm(ridge_w2_logloss_downsampled, ridge_a2_logloss_downsampled)
```

Second set of models with logloss and downsampling (w2 and a2). Note that this suffers from unidentifiability in lambda (from Till).

```{r: Second ridge regression w/o downsampling}
# Black magic
par_grid <-  expand.grid(alpha = 0,
                        lambda = 10^seq(-6, -8,
                                     length.out = 8))
# Black magic
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

# Set seed
set.seed(152)

# Second ridge model for water temperature
ridge_w2_logloss <- train(w2, 
                          data = training, 
                          method = "glmnet", 
                          metric = "logLoss",
                          tuneGrid = par_grid,
                          trControl = control_logloss)

# Second ridge model for water temperature
ridge_a2_logloss <- train(a2, 
                          data = training, 
                          method = "glmnet", 
                          metric = "logLoss",
                          tuneGrid = par_grid,
                          trControl = control_logloss)
# Black magic
stopCluster(cl)

# Save models
write_rds(ridge_w2_logloss, "assessment/ridge_w2_logloss.rds")
write_rds(ridge_a2_logloss, "assessment/ridge_a2_logloss.rds")

# Remove models
rm(ridge_w2_logloss, ridge_a2_logloss)
```

### Step 7: Logistic regressions with random effecs

```{r: First random effects logistic}
# Random effects model for water temperature
w1_re <- summerkill ~ long + lat + season + variance_after_ice_30 + variance_after_ice_60 + log_schmidt +
  cumulative_above_10 + ice_duration + water_pca + (1 | site_id)

# Black magic
re_w1 <- glmer(w1_re,
               data = training, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 10)

### Warning messages:
### 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
###   unable to evaluate scaled gradient
### 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
###    Hessian is numerically singular: parameters are not uniquely determined
   
# Black magic (changed from lmer to glmer; removed unused argument (REML = FALSE))
rf_w1 <- glmer(w1_re, 
               data = training,
               family = binomial,
               control = glmerControl(optimizer = 'optimx',
                                      optCtrl = list(method = 'L-BFGS-B')))

# Random effects model for air temperature
a1_re <- summerkill ~ long + lat + season + air_pca + (1 | site_id)
   
# Black magic
re_a1 <- glmer(a1_re,
               data = training, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 10)

### Warning messages:
### 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
###   unable to evaluate scaled gradient
### 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
###    Hessian is numerically singular: parameters are not uniquely determined
   
# Black magic (changed from lmer to glmer; removed unused argument (REML = FALSE))
rf_a1 <- glmer(a1_re, 
               data = training,
               family = binomial,
               control = glmerControl(optimizer = 'optimx',
                                      optCtrl = list(method = 'L-BFGS-B')))

# Save models
write_rds(re_w1, "assessment/re_w1.rds")
write_rds(rf_w1, "assessment/rf_w1.rds")
write_rds(re_a1, "assessment/re_a1.rds")
write_rds(rf_a1, "assessment/rf_a1.rds")

# Remove models
rm(re_w1, rf_w1,
   re_a1, rf_a1)
```

######################################
Proceed to `04_assess_models.Rmd`
######################################
